{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8156597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 23:17:46.470558: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-07 23:17:46.470634: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-07 23:17:46.474152: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-07 23:17:46.495024: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-07 23:17:49.113031: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#import required libraries\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, matthews_corrcoef, precision_score, f1_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, SimpleRNN,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "import keras\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
    "\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a9bc0f8-8892-44d1-9f4b-d0c89a38ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-tensorrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08f9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "#!pip install imutils\n",
    "#!pip install scikit-learn\n",
    "#!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8016367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to load the dataset images from device\n",
    "\n",
    "class SimpleDatasetLoader:\n",
    "    # Method: Constructor\n",
    "    def __init__(self, preprocessors=None):\n",
    "        \"\"\"\n",
    "        :param preprocessors: List of image preprocessors\n",
    "        \"\"\"\n",
    "        self.preprocessors = preprocessors\n",
    "\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "\n",
    "    # Method: Used to load a list of images for pre-processing\n",
    "    def load(self, image_paths, verbose=-1):\n",
    "        \"\"\"\n",
    "        :param image_paths: List of image paths\n",
    "        :param verbose: Parameter for printing information to console\n",
    "        :return: Tuple of data and labels\n",
    "        \"\"\"\n",
    "        data, labels = [], []\n",
    "\n",
    "        for i, image_path in enumerate(image_paths):\n",
    "            image = cv2.imread(image_path)\n",
    "            label = image_path.split(os.path.sep)[-2]\n",
    "\n",
    "            if self.preprocessors is not None:\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.preprocess(image)\n",
    "\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "            if verbose > 0 and i > 0 and (i+1) % verbose == 0:\n",
    "                print('[INFO]: Processed {}/{}'.format(i+1, len(image_paths)))\n",
    "\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db2af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Preprocessror \n",
    "class SimplePreprocessor:\n",
    "    # Method: Constructor\n",
    "    def __init__(self, width, height, interpolation=cv2.INTER_AREA):\n",
    "        \"\"\"\n",
    "        :param width: Image width\n",
    "        :param height: Image height\n",
    "        :param interpolation: Interpolation algorithm\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    # Method: Used to resize the image to a fixed size (ignoring the aspect ratio)\n",
    "    def preprocess(self, image):\n",
    "        \"\"\"\n",
    "        :param image: Image\n",
    "        :return: Re-sized image\n",
    "        \"\"\"\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11731516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from __main__ import SimplePreprocessor\n",
    "from __main__ import SimpleDatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253976fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Images loading....\n",
      "[INFO]: Processed 1000/27558\n",
      "[INFO]: Processed 2000/27558\n",
      "[INFO]: Processed 3000/27558\n",
      "[INFO]: Processed 4000/27558\n",
      "[INFO]: Processed 5000/27558\n",
      "[INFO]: Processed 6000/27558\n",
      "[INFO]: Processed 7000/27558\n",
      "[INFO]: Processed 8000/27558\n",
      "[INFO]: Processed 9000/27558\n",
      "[INFO]: Processed 10000/27558\n",
      "[INFO]: Processed 11000/27558\n",
      "[INFO]: Processed 12000/27558\n",
      "[INFO]: Processed 13000/27558\n",
      "[INFO]: Processed 14000/27558\n",
      "[INFO]: Processed 15000/27558\n",
      "[INFO]: Processed 16000/27558\n",
      "[INFO]: Processed 17000/27558\n",
      "[INFO]: Processed 18000/27558\n",
      "[INFO]: Processed 19000/27558\n",
      "[INFO]: Processed 20000/27558\n",
      "[INFO]: Processed 21000/27558\n",
      "[INFO]: Processed 22000/27558\n",
      "[INFO]: Processed 23000/27558\n",
      "[INFO]: Processed 24000/27558\n",
      "[INFO]: Processed 25000/27558\n",
      "[INFO]: Processed 26000/27558\n",
      "[INFO]: Processed 27000/27558\n",
      "(27558, 224, 224, 3)\n",
      "(27558,)\n"
     ]
    }
   ],
   "source": [
    "# Function to load and preprocess data using SimpleDatasetLoader\n",
    "def load_and_preprocess_data(image_paths, target_size):\n",
    "    sp = SimplePreprocessor(target_size[0], target_size[1])\n",
    "    sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "    data, labels = sdl.load(image_paths, verbose=1000)\n",
    "\n",
    "    print(data.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "    #labels = to_categorical(labels)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "\n",
    "# Get list of image paths\n",
    "image_paths = list(paths.list_images(\"../cell_images/\"))\n",
    "\n",
    "# Define target size for images\n",
    "target_size = (224, 224)  # Change this to your desired size\n",
    "\n",
    "# Load and preprocess data\n",
    "print('[INFO]: Images loading....')\n",
    "data, labels = load_and_preprocess_data(image_paths, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8bade7-be6f-4028-8313-11ad6e920fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 23:18:54.345439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38380 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:65:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/862 [==============================] - 1703s 2s/step\n",
      "(27558, 100352)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import  ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "with tf.device('/CPU:0'):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(target_size[0], target_size[1], 3))\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "    features = model.predict(data, batch_size=32, verbose=1)\n",
    "\n",
    "# Flatten the features\n",
    "features_flatten = features.reshape(features.shape[0], -1)\n",
    "    \n",
    "print(features_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b28dc9e4-da07-475a-8f3b-6704bc2fc246",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = features_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea8357b-fc36-46ea-a4d9-5eb4c0dda9fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "#tf.config.experimental.enable_tensor_float_32_execution(True)\n",
    "#tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "#tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "# Initialize a DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Average Accuracy', 'Average Sensitivity', 'Average Specificity',\n",
    "                                   'Average AUC-ROC', 'Average MCC', 'Average Precision', 'Average F1 Score',\n",
    "                                   'Memory Used (MB)', 'Time (s)'])\n",
    "\n",
    "# Function to evaluate a model\n",
    "def evaluate_model(model, name, data, labels):\n",
    "    if name == \"VGG16\":\n",
    "        labels = to_categorical(labels)\n",
    "\n",
    "    elif name == \"VGG19\":  \n",
    "        labels = to_categorical(labels)\n",
    "    else:\n",
    "        data = data\n",
    "    accuracy_list = []\n",
    "    sensitivity_list = []\n",
    "    specificity_list = []\n",
    "    auc_roc_list = []\n",
    "    mcc_list = []\n",
    "    precision_list = []\n",
    "    f1_list = []\n",
    "    time_start = time.time()\n",
    "    memory_start = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    if name == \"VGG16\" or name == \"VGG19\":\n",
    "\n",
    "\n",
    "        with tf.device('/GPU:0'):\n",
    "            tf.random.set_seed(0)\n",
    "            for fold, (train_index, test_index) in enumerate(skf.split(data, labels.argmax(axis=1))):\n",
    "                print(f'\\n[INFO] Fold {fold + 1} / 10 for {name}')\n",
    "\n",
    "                X_train, X_test = data[train_index], data[test_index]\n",
    "                y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "\n",
    "                # Adding early stopping to prevent overfitting\n",
    "                early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "                keras.utils.set_random_seed(0)\n",
    "                np.random.seed(0)\n",
    "                tf.random.set_seed(0)\n",
    "                #tf.config.run_functions_eagerly(True)\n",
    "                tf.data.experimental.enable_debug_mode()\n",
    "                # Train the model\n",
    "                # Example of using tf.data.Dataset\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(64)\n",
    "\n",
    "                model.fit(train_dataset, epochs=20, callbacks=[early_stopping])\n",
    "\n",
    "                # Evaluate the model\n",
    "                predictions = model.predict(X_test)\n",
    "                y_pred = np.argmax(predictions, axis=1)\n",
    "                y_test_encoded = np.argmax(y_test, axis=1)\n",
    "\n",
    "                \n",
    "                # Calculate evaluation metrics for the current fold\n",
    "                accuracy = np.mean(y_pred == y_test_encoded)\n",
    "                sensitivity = recall_score(y_test_encoded, y_pred, pos_label=1)\n",
    "                specificity = recall_score(y_test_encoded, y_pred, pos_label=0)\n",
    "                auc_roc = roc_auc_score(y_test_encoded, y_pred)\n",
    "                mcc = matthews_corrcoef(y_test_encoded, y_pred)\n",
    "                precision = precision_score(y_test_encoded, y_pred, pos_label=1)\n",
    "                f1 = f1_score(y_test_encoded, y_pred, pos_label=1)\n",
    "                # Append metrics to lists\n",
    "                accuracy_list.append(accuracy)\n",
    "                sensitivity_list.append(sensitivity)\n",
    "                specificity_list.append(specificity)\n",
    "                auc_roc_list.append(auc_roc)\n",
    "                mcc_list.append(mcc)\n",
    "                precision_list.append(precision)\n",
    "                f1_list.append(f1)\n",
    "\n",
    "                # Print metrics for the current fold\n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Sensitivity: {sensitivity}\")\n",
    "                print(f\"Specificity: {specificity}\")\n",
    "                print(f\"AUC-ROC: {auc_roc}\")\n",
    "                print(f\"MCC: {mcc}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"F1 Score: {f1}\")\n",
    "                gc.collect()\n",
    "\n",
    "            # Calculate average metrics\n",
    "            average_accuracy = np.mean(accuracy_list)\n",
    "            average_sensitivity = np.mean(sensitivity_list)\n",
    "            average_specificity = np.mean(specificity_list)\n",
    "            average_auc_roc = np.mean(auc_roc_list)\n",
    "            average_mcc = np.mean(mcc_list)\n",
    "            average_precision = np.mean(precision_list)\n",
    "            average_f1 = np.mean(f1_list)\n",
    "\n",
    "            time_end = time.time()\n",
    "            memory_end = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2\n",
    "            del X_train, X_test, y_train, y_test\n",
    "            gc.collect()\n",
    "            tf.keras.backend.clear_session()\n",
    "    else:\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(data, labels)):\n",
    "            print(f'\\n[INFO] Fold {fold + 1} / 10 for {name}')\n",
    "\n",
    "            X_train, X_test = data[train_index], data[test_index]\n",
    "            y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            predictions = model.predict(X_test)\n",
    "            y_pred = predictions\n",
    "            y_test_encoded = y_test\n",
    "\n",
    "            # Calculate evaluation metrics for the current fold\n",
    "            accuracy = np.mean(y_pred == y_test_encoded)\n",
    "            sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "            specificity = recall_score(y_test, y_pred, pos_label=0)\n",
    "            auc_roc = roc_auc_score(y_test, predictions)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "            f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "            # Append metrics to lists\n",
    "            accuracy_list.append(accuracy)\n",
    "            sensitivity_list.append(sensitivity)\n",
    "            specificity_list.append(specificity)\n",
    "            auc_roc_list.append(auc_roc)\n",
    "            mcc_list.append(mcc)\n",
    "            precision_list.append(precision)\n",
    "            f1_list.append(f1)\n",
    "\n",
    "            # Print metrics for the current fold\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Sensitivity: {sensitivity}\")\n",
    "            print(f\"Specificity: {specificity}\")\n",
    "            print(f\"AUC-ROC: {auc_roc}\")\n",
    "            print(f\"MCC: {mcc}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"F1 Score: {f1}\")\n",
    "            gc.collect()\n",
    "\n",
    "        # Calculate average metrics\n",
    "        average_accuracy = np.mean(accuracy_list)\n",
    "        average_sensitivity = np.mean(sensitivity_list)\n",
    "        average_specificity = np.mean(specificity_list)\n",
    "        average_auc_roc = np.mean(auc_roc_list)\n",
    "        average_mcc = np.mean(mcc_list)\n",
    "        average_precision = np.mean(precision_list)\n",
    "        average_f1 = np.mean(f1_list)\n",
    "\n",
    "        time_end = time.time()\n",
    "        memory_end = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2\n",
    "        \n",
    "\n",
    "    # Append results to DataFrame\n",
    "    results_df.loc[len(results_df)] = [name, average_accuracy, average_sensitivity, average_specificity,\n",
    "                                       average_auc_roc, average_mcc, average_precision, average_f1,\n",
    "                                       memory_end - memory_start, time_end - time_start]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "743d006a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9390420899854862\n",
      "Sensitivity: 0.9375907111756169\n",
      "Specificity: 0.9404934687953556\n",
      "AUC-ROC: 0.9390420899854861\n",
      "MCC: 0.8780878793637907\n",
      "Precision: 0.9403202328966521\n",
      "F1 Score: 0.938953488372093\n",
      "\n",
      "[INFO] Fold 2 / 10 for LR\n",
      "Accuracy: 0.9470246734397678\n",
      "Sensitivity: 0.951378809869376\n",
      "Specificity: 0.9426705370101597\n",
      "AUC-ROC: 0.9470246734397678\n",
      "MCC: 0.894083248484042\n",
      "Precision: 0.9431654676258993\n",
      "F1 Score: 0.9472543352601156\n",
      "\n",
      "[INFO] Fold 3 / 10 for LR\n",
      "Accuracy: 0.9412191582002902\n",
      "Sensitivity: 0.9448476052249637\n",
      "Specificity: 0.9375907111756169\n",
      "AUC-ROC: 0.9412191582002903\n",
      "MCC: 0.8824615530272384\n",
      "Precision: 0.9380403458213257\n",
      "F1 Score: 0.9414316702819957\n",
      "\n",
      "[INFO] Fold 4 / 10 for LR\n",
      "Accuracy: 0.9444847605224964\n",
      "Sensitivity: 0.9477503628447025\n",
      "Specificity: 0.9412191582002902\n",
      "AUC-ROC: 0.9444847605224963\n",
      "MCC: 0.8889884818753946\n",
      "Precision: 0.9416005767844268\n",
      "F1 Score: 0.9446654611211572\n",
      "\n",
      "[INFO] Fold 5 / 10 for LR\n",
      "Accuracy: 0.9299709724238027\n",
      "Sensitivity: 0.9317851959361393\n",
      "Specificity: 0.9281567489114659\n",
      "AUC-ROC: 0.9299709724238027\n",
      "MCC: 0.8599476057412946\n",
      "Precision: 0.928416485900217\n",
      "F1 Score: 0.9300977906555595\n",
      "\n",
      "[INFO] Fold 6 / 10 for LR\n",
      "Accuracy: 0.9386792452830188\n",
      "Sensitivity: 0.9354136429608128\n",
      "Specificity: 0.941944847605225\n",
      "AUC-ROC: 0.9386792452830188\n",
      "MCC: 0.8773772037447772\n",
      "Precision: 0.9415631848064281\n",
      "F1 Score: 0.9384783400072806\n",
      "\n",
      "[INFO] Fold 7 / 10 for LR\n",
      "Accuracy: 0.9386792452830188\n",
      "Sensitivity: 0.9368650217706821\n",
      "Specificity: 0.9404934687953556\n",
      "AUC-ROC: 0.9386792452830188\n",
      "MCC: 0.8773642661107385\n",
      "Precision: 0.9402767662053897\n",
      "F1 Score: 0.9385677935296255\n",
      "\n",
      "[INFO] Fold 8 / 10 for LR\n",
      "Accuracy: 0.9386792452830188\n",
      "Sensitivity: 0.9339622641509434\n",
      "Specificity: 0.9433962264150944\n",
      "AUC-ROC: 0.9386792452830189\n",
      "MCC: 0.8773975354689548\n",
      "Precision: 0.9428571428571428\n",
      "F1 Score: 0.9383886255924171\n",
      "\n",
      "[INFO] Fold 9 / 10 for LR\n",
      "Accuracy: 0.949546279491833\n",
      "Sensitivity: 0.9506172839506173\n",
      "Specificity: 0.9484760522496372\n",
      "AUC-ROC: 0.9495466681001272\n",
      "MCC: 0.8990947576905715\n",
      "Precision: 0.9485507246376812\n",
      "F1 Score: 0.9495828799419659\n",
      "\n",
      "[INFO] Fold 10 / 10 for LR\n",
      "Accuracy: 0.947005444646098\n",
      "Sensitivity: 0.9557329462989841\n",
      "Specificity: 0.9382716049382716\n",
      "AUC-ROC: 0.9470022756186278\n",
      "MCC: 0.8941459289124787\n",
      "Precision: 0.9393723252496433\n",
      "F1 Score: 0.9474820143884892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# SVM\n",
    "lr_model = LogisticRegression(n_jobs=-1, random_state=0)\n",
    "evaluate_model(lr_model, 'LR', data, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ad87131-764c-448b-8476-2e415110115e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for NB\n",
      "Accuracy: 0.8102322206095791\n",
      "Sensitivity: 0.8403483309143687\n",
      "Specificity: 0.7801161103047896\n",
      "AUC-ROC: 0.8102322206095791\n",
      "MCC: 0.6215930107212115\n",
      "Precision: 0.7926078028747433\n",
      "F1 Score: 0.8157802042972878\n",
      "\n",
      "[INFO] Fold 2 / 10 for NB\n",
      "Accuracy: 0.8134978229317852\n",
      "Sensitivity: 0.8352685050798259\n",
      "Specificity: 0.7917271407837445\n",
      "AUC-ROC: 0.8134978229317852\n",
      "MCC: 0.627590837267297\n",
      "Precision: 0.8004172461752433\n",
      "F1 Score: 0.8174715909090908\n",
      "\n",
      "[INFO] Fold 3 / 10 for NB\n",
      "Accuracy: 0.8200290275761973\n",
      "Sensitivity: 0.8563134978229318\n",
      "Specificity: 0.783744557329463\n",
      "AUC-ROC: 0.8200290275761974\n",
      "MCC: 0.6417500943467965\n",
      "Precision: 0.7983761840324763\n",
      "F1 Score: 0.8263305322128853\n",
      "\n",
      "[INFO] Fold 4 / 10 for NB\n",
      "Accuracy: 0.8167634252539913\n",
      "Sensitivity: 0.8497822931785196\n",
      "Specificity: 0.783744557329463\n",
      "AUC-ROC: 0.8167634252539913\n",
      "MCC: 0.6349127849578589\n",
      "Precision: 0.7971409121851599\n",
      "F1 Score: 0.8226203020723568\n",
      "\n",
      "[INFO] Fold 5 / 10 for NB\n",
      "Accuracy: 0.816400580551524\n",
      "Sensitivity: 0.841799709724238\n",
      "Specificity: 0.7910014513788098\n",
      "AUC-ROC: 0.816400580551524\n",
      "MCC: 0.6336192046497019\n",
      "Precision: 0.8011049723756906\n",
      "F1 Score: 0.8209483368719036\n",
      "\n",
      "[INFO] Fold 6 / 10 for NB\n",
      "Accuracy: 0.7949927431059507\n",
      "Sensitivity: 0.8113207547169812\n",
      "Specificity: 0.7786647314949202\n",
      "AUC-ROC: 0.7949927431059507\n",
      "MCC: 0.590300322982157\n",
      "Precision: 0.7856640899508082\n",
      "F1 Score: 0.7982863263120314\n",
      "\n",
      "[INFO] Fold 7 / 10 for NB\n",
      "Accuracy: 0.8113207547169812\n",
      "Sensitivity: 0.8374455732946299\n",
      "Specificity: 0.7851959361393324\n",
      "AUC-ROC: 0.8113207547169812\n",
      "MCC: 0.6234931669291748\n",
      "Precision: 0.7958620689655173\n",
      "F1 Score: 0.8161244695898162\n",
      "\n",
      "[INFO] Fold 8 / 10 for NB\n",
      "Accuracy: 0.8207547169811321\n",
      "Sensitivity: 0.8359941944847605\n",
      "Specificity: 0.8055152394775036\n",
      "AUC-ROC: 0.820754716981132\n",
      "MCC: 0.6418076121769871\n",
      "Precision: 0.8112676056338028\n",
      "F1 Score: 0.8234453180843461\n",
      "\n",
      "[INFO] Fold 9 / 10 for NB\n",
      "Accuracy: 0.8228675136116153\n",
      "Sensitivity: 0.85039941902687\n",
      "Specificity: 0.795355587808418\n",
      "AUC-ROC: 0.822877503417644\n",
      "MCC: 0.6467271031147909\n",
      "Precision: 0.8059187887130076\n",
      "F1 Score: 0.8275618374558305\n",
      "\n",
      "[INFO] Fold 10 / 10 for NB\n",
      "Accuracy: 0.8134301270417423\n",
      "Sensitivity: 0.8410740203193033\n",
      "Specificity: 0.7857661583151779\n",
      "AUC-ROC: 0.8134200893172407\n",
      "MCC: 0.6278090228513047\n",
      "Precision: 0.7971114167812929\n",
      "F1 Score: 0.8185028248587571\n"
     ]
    }
   ],
   "source": [
    "#NB\n",
    "nb_model = GaussianNB()\n",
    "evaluate_model(nb_model, 'NB', data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04aacd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for KNN\n",
      "Accuracy: 0.7235123367198839\n",
      "Sensitivity: 0.9731494920174165\n",
      "Specificity: 0.47387518142235124\n",
      "AUC-ROC: 0.7235123367198839\n",
      "MCC: 0.5159302690657588\n",
      "Precision: 0.649080348499516\n",
      "F1 Score: 0.7787456445993032\n",
      "\n",
      "[INFO] Fold 2 / 10 for KNN\n",
      "Accuracy: 0.7264150943396226\n",
      "Sensitivity: 0.9709724238026125\n",
      "Specificity: 0.4818577648766328\n",
      "AUC-ROC: 0.7264150943396226\n",
      "MCC: 0.5191699914900667\n",
      "Precision: 0.652046783625731\n",
      "F1 Score: 0.7801749271137026\n",
      "\n",
      "[INFO] Fold 3 / 10 for KNN\n",
      "Accuracy: 0.7343976777939042\n",
      "Sensitivity: 0.9775036284470247\n",
      "Specificity: 0.49129172714078373\n",
      "AUC-ROC: 0.7343976777939042\n",
      "MCC: 0.5364767597351032\n",
      "Precision: 0.65771484375\n",
      "F1 Score: 0.7863397548161121\n",
      "\n",
      "[INFO] Fold 4 / 10 for KNN\n",
      "Accuracy: 0.7187953555878084\n",
      "Sensitivity: 0.9702467343976778\n",
      "Specificity: 0.46734397677793904\n",
      "AUC-ROC: 0.7187953555878084\n",
      "MCC: 0.5062697479116127\n",
      "Precision: 0.6455818445195558\n",
      "F1 Score: 0.775297187590606\n",
      "\n",
      "[INFO] Fold 5 / 10 for KNN\n",
      "Accuracy: 0.7362119013062409\n",
      "Sensitivity: 0.9644412191582002\n",
      "Specificity: 0.5079825834542816\n",
      "AUC-ROC: 0.7362119013062409\n",
      "MCC: 0.5309656102572046\n",
      "Precision: 0.6621823617339312\n",
      "F1 Score: 0.7852289512555392\n",
      "\n",
      "[INFO] Fold 6 / 10 for KNN\n",
      "Accuracy: 0.7144412191582002\n",
      "Sensitivity: 0.9600870827285921\n",
      "Specificity: 0.46879535558780844\n",
      "AUC-ROC: 0.7144412191582002\n",
      "MCC: 0.4924051185716155\n",
      "Precision: 0.6437956204379562\n",
      "F1 Score: 0.7707544421788524\n",
      "\n",
      "[INFO] Fold 7 / 10 for KNN\n",
      "Accuracy: 0.717343976777939\n",
      "Sensitivity: 0.969521044992743\n",
      "Specificity: 0.465166908563135\n",
      "AUC-ROC: 0.717343976777939\n",
      "MCC: 0.5034041824624543\n",
      "Precision: 0.6444766039556199\n",
      "F1 Score: 0.7742683280208635\n",
      "\n",
      "[INFO] Fold 8 / 10 for KNN\n",
      "Accuracy: 0.7224238026124818\n",
      "Sensitivity: 0.9658925979680697\n",
      "Specificity: 0.47895500725689405\n",
      "AUC-ROC: 0.7224238026124818\n",
      "MCC: 0.5093071679182954\n",
      "Precision: 0.6495851634943876\n",
      "F1 Score: 0.7767726874817625\n",
      "\n",
      "[INFO] Fold 9 / 10 for KNN\n",
      "Accuracy: 0.7357531760435572\n",
      "Sensitivity: 0.9789397240377633\n",
      "Specificity: 0.4927431059506531\n",
      "AUC-ROC: 0.7358414149942082\n",
      "MCC: 0.5397169982259223\n",
      "Precision: 0.6585246702491451\n",
      "F1 Score: 0.7873831775700934\n",
      "\n",
      "[INFO] Fold 10 / 10 for KNN\n",
      "Accuracy: 0.7361161524500908\n",
      "Sensitivity: 0.9724238026124818\n",
      "Specificity: 0.49963689179375453\n",
      "AUC-ROC: 0.7360303472031182\n",
      "MCC: 0.5357720897677904\n",
      "Precision: 0.6604238541153278\n",
      "F1 Score: 0.7866157910184913\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KNN\n",
    "knn_model = KNeighborsClassifier()\n",
    "evaluate_model(knn_model, 'KNN', data, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46ce2ad5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for Random Forest\n",
      "Accuracy: 0.897677793904209\n",
      "Sensitivity: 0.8613933236574746\n",
      "Specificity: 0.9339622641509434\n",
      "AUC-ROC: 0.8976777939042091\n",
      "MCC: 0.7974581671248175\n",
      "Precision: 0.9287949921752738\n",
      "F1 Score: 0.8938253012048192\n",
      "\n",
      "[INFO] Fold 2 / 10 for Random Forest\n",
      "Accuracy: 0.8991291727140783\n",
      "Sensitivity: 0.8679245283018868\n",
      "Specificity: 0.93033381712627\n",
      "AUC-ROC: 0.8991291727140784\n",
      "MCC: 0.7998174773597547\n",
      "Precision: 0.9256965944272446\n",
      "F1 Score: 0.8958801498127341\n",
      "\n",
      "[INFO] Fold 3 / 10 for Random Forest\n",
      "Accuracy: 0.9125544267053701\n",
      "Sensitivity: 0.8925979680696662\n",
      "Specificity: 0.9325108853410741\n",
      "AUC-ROC: 0.91255442670537\n",
      "MCC: 0.8257668557858249\n",
      "Precision: 0.9297052154195011\n",
      "F1 Score: 0.9107737874861164\n",
      "\n",
      "[INFO] Fold 4 / 10 for Random Forest\n",
      "Accuracy: 0.9107402031930334\n",
      "Sensitivity: 0.8831640058055152\n",
      "Specificity: 0.9383164005805515\n",
      "AUC-ROC: 0.9107402031930334\n",
      "MCC: 0.8227326479665596\n",
      "Precision: 0.934715821812596\n",
      "F1 Score: 0.9082089552238805\n",
      "\n",
      "[INFO] Fold 5 / 10 for Random Forest\n",
      "Accuracy: 0.8947750362844702\n",
      "Sensitivity: 0.8606676342525399\n",
      "Specificity: 0.9288824383164006\n",
      "AUC-ROC: 0.8947750362844702\n",
      "MCC: 0.7913934992117444\n",
      "Precision: 0.9236760124610592\n",
      "F1 Score: 0.8910593538692713\n",
      "\n",
      "[INFO] Fold 6 / 10 for Random Forest\n",
      "Accuracy: 0.8835268505079826\n",
      "Sensitivity: 0.8410740203193033\n",
      "Specificity: 0.9259796806966618\n",
      "AUC-ROC: 0.8835268505079826\n",
      "MCC: 0.7698335741025729\n",
      "Precision: 0.9191118160190325\n",
      "F1 Score: 0.8783630162940508\n",
      "\n",
      "[INFO] Fold 7 / 10 for Random Forest\n",
      "Accuracy: 0.9034833091436865\n",
      "Sensitivity: 0.8693759071117562\n",
      "Specificity: 0.9375907111756169\n",
      "AUC-ROC: 0.9034833091436865\n",
      "MCC: 0.8088507087531799\n",
      "Precision: 0.9330218068535826\n",
      "F1 Score: 0.9000751314800902\n",
      "\n",
      "[INFO] Fold 8 / 10 for Random Forest\n",
      "Accuracy: 0.8936865021770682\n",
      "Sensitivity: 0.862844702467344\n",
      "Specificity: 0.9245283018867925\n",
      "AUC-ROC: 0.8936865021770682\n",
      "MCC: 0.788875217063958\n",
      "Precision: 0.9195668986852281\n",
      "F1 Score: 0.8903032572070385\n",
      "\n",
      "[INFO] Fold 9 / 10 for Random Forest\n",
      "Accuracy: 0.9143375680580762\n",
      "Sensitivity: 0.8903413217138707\n",
      "Specificity: 0.9383164005805515\n",
      "AUC-ROC: 0.9143288611472111\n",
      "MCC: 0.829624976546281\n",
      "Precision: 0.935163996948894\n",
      "F1 Score: 0.9122023809523808\n",
      "\n",
      "[INFO] Fold 10 / 10 for Random Forest\n",
      "Accuracy: 0.8969147005444646\n",
      "Sensitivity: 0.8751814223512336\n",
      "Specificity: 0.9186637618010167\n",
      "AUC-ROC: 0.8969225920761251\n",
      "MCC: 0.7945867233457369\n",
      "Precision: 0.9150227617602428\n",
      "F1 Score: 0.8946587537091988\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "evaluate_model(rf_model, 'Random Forest', data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa8cf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for LGBM\n",
      "[LightGBM] [Info] Number of positive: 12401, number of negative: 12401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 48.738065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20004802\n",
      "[LightGBM] [Info] Number of data points in the train set: 24802, number of used features: 95357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.9386792452830188\n",
      "Sensitivity: 0.9412191582002902\n",
      "Specificity: 0.9361393323657474\n",
      "AUC-ROC: 0.9386792452830187\n",
      "MCC: 0.8773698107409595\n",
      "Precision: 0.9364620938628159\n",
      "F1 Score: 0.9388346000723851\n",
      "\n",
      "[INFO] Fold 2 / 10 for LGBM\n",
      "[LightGBM] [Info] Number of positive: 12401, number of negative: 12401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 48.438812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20009063\n",
      "[LightGBM] [Info] Number of data points in the train set: 24802, number of used features: 95365\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.941944847605225\n",
      "Sensitivity: 0.9462989840348331\n",
      "Specificity: 0.9375907111756169\n",
      "AUC-ROC: 0.9419448476052251\n",
      "MCC: 0.8839232115694506\n",
      "Precision: 0.9381294964028777\n",
      "F1 Score: 0.9421965317919077\n",
      "\n",
      "[INFO] Fold 3 / 10 for LGBM\n",
      "[LightGBM] [Info] Number of positive: 12401, number of negative: 12401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 48.496746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20012312\n",
      "[LightGBM] [Info] Number of data points in the train set: 24802, number of used features: 95336\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.9415820029027576\n",
      "Sensitivity: 0.9492017416545718\n",
      "Specificity: 0.9339622641509434\n",
      "AUC-ROC: 0.9415820029027576\n",
      "MCC: 0.8832665774157331\n",
      "Precision: 0.9349535382416011\n",
      "F1 Score: 0.9420237666546633\n",
      "\n",
      "[INFO] Fold 4 / 10 for LGBM\n",
      "[LightGBM] [Info] Number of positive: 12401, number of negative: 12401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 49.124786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20010694\n",
      "[LightGBM] [Info] Number of data points in the train set: 24802, number of used features: 95323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.9394049346879536\n",
      "Sensitivity: 0.9354136429608128\n",
      "Specificity: 0.9433962264150944\n",
      "AUC-ROC: 0.9394049346879535\n",
      "MCC: 0.8788378703165628\n",
      "Precision: 0.9429407461594733\n",
      "F1 Score: 0.9391621129326047\n",
      "\n",
      "[INFO] Fold 5 / 10 for LGBM\n",
      "[LightGBM] [Info] Number of positive: 12401, number of negative: 12401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 50.048681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20007503\n",
      "[LightGBM] [Info] Number of data points in the train set: 24802, number of used features: 95339\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.9325108853410741\n",
      "Sensitivity: 0.9281567489114659\n",
      "Specificity: 0.9368650217706821\n",
      "AUC-ROC: 0.9325108853410741\n",
      "MCC: 0.8650545715852095\n",
      "Precision: 0.9363103953147877\n",
      "F1 Score: 0.9322157434402333\n",
      "\n",
      "[INFO] Fold 6 / 10 for LGBM\n",
      "[LightGBM] [Info] Number of positive: 12401, number of negative: 12401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 50.300840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20005024\n",
      "[LightGBM] [Info] Number of data points in the train set: 24802, number of used features: 95314\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.9267053701015965\n",
      "Sensitivity: 0.9216255442670537\n",
      "Specificity: 0.9317851959361393\n",
      "AUC-ROC: 0.9267053701015966\n",
      "MCC: 0.8534547875107431\n",
      "Precision: 0.9310850439882697\n",
      "F1 Score: 0.9263311451495259\n",
      "\n",
      "[INFO] Fold 7 / 10 for LGBM\n",
      "[LightGBM] [Info] Number of positive: 12401, number of negative: 12401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 49.253575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20005512\n",
      "[LightGBM] [Info] Number of data points in the train set: 24802, number of used features: 95344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.933599419448476\n",
      "Sensitivity: 0.9281567489114659\n",
      "Specificity: 0.9390420899854862\n",
      "AUC-ROC: 0.933599419448476\n",
      "MCC: 0.8672502209403952\n",
      "Precision: 0.9383712399119589\n",
      "F1 Score: 0.9332360452389639\n",
      "\n",
      "[INFO] Fold 8 / 10 for LGBM\n",
      "[LightGBM] [Info] Number of positive: 12401, number of negative: 12401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 50.284038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20004293\n",
      "[LightGBM] [Info] Number of data points in the train set: 24802, number of used features: 95306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.931422351233672\n",
      "Sensitivity: 0.9230769230769231\n",
      "Specificity: 0.9397677793904209\n",
      "AUC-ROC: 0.931422351233672\n",
      "MCC: 0.8629649152446013\n",
      "Precision: 0.9387453874538746\n",
      "F1 Score: 0.9308452250274425\n",
      "\n",
      "[INFO] Fold 9 / 10 for LGBM\n",
      "[LightGBM] [Info] Number of positive: 12402, number of negative: 12401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 50.233208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20012771\n",
      "[LightGBM] [Info] Number of data points in the train set: 24803, number of used features: 95355\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000081\n",
      "[LightGBM] [Info] Start training from score 0.000081\n",
      "Accuracy: 0.9477313974591651\n",
      "Sensitivity: 0.9426289034132171\n",
      "Specificity: 0.9528301886792453\n",
      "AUC-ROC: 0.9477295460462313\n",
      "MCC: 0.8955086471450748\n",
      "Precision: 0.9523110785033015\n",
      "F1 Score: 0.9474452554744526\n",
      "\n",
      "[INFO] Fold 10 / 10 for LGBM\n",
      "[LightGBM] [Info] Number of positive: 12401, number of negative: 12402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 49.652070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20008750\n",
      "[LightGBM] [Info] Number of data points in the train set: 24803, number of used features: 95344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499980 -> initscore=-0.000081\n",
      "[LightGBM] [Info] Start training from score -0.000081\n",
      "Accuracy: 0.9422867513611616\n",
      "Sensitivity: 0.9542815674891146\n",
      "Specificity: 0.9302832244008714\n",
      "AUC-ROC: 0.9422823959449931\n",
      "MCC: 0.8848264306031599\n",
      "Precision: 0.9319631467044649\n",
      "F1 Score: 0.9429903191107923\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "# LGBM\n",
    "lgb_model = lightgbm.LGBMClassifier(random_state=0, n_jobs = -1)\n",
    "evaluate_model(lgb_model, 'LGBM', data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d62fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a CSV file\n",
    "results_df.to_csv('DS1_ResNet50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53e08610-4212-476c-8792-3406ab2bbe44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Sensitivity</th>\n",
       "      <th>Average Specificity</th>\n",
       "      <th>Average AUC-ROC</th>\n",
       "      <th>Average MCC</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average F1 Score</th>\n",
       "      <th>Memory Used (MB)</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.941433</td>\n",
       "      <td>0.942594</td>\n",
       "      <td>0.940271</td>\n",
       "      <td>0.941433</td>\n",
       "      <td>0.882895</td>\n",
       "      <td>0.940416</td>\n",
       "      <td>0.941490</td>\n",
       "      <td>6615.441406</td>\n",
       "      <td>9456.957862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.814029</td>\n",
       "      <td>0.839975</td>\n",
       "      <td>0.788083</td>\n",
       "      <td>0.814029</td>\n",
       "      <td>0.628960</td>\n",
       "      <td>0.798547</td>\n",
       "      <td>0.818707</td>\n",
       "      <td>10549.937500</td>\n",
       "      <td>558.072101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.726541</td>\n",
       "      <td>0.970318</td>\n",
       "      <td>0.482765</td>\n",
       "      <td>0.726541</td>\n",
       "      <td>0.518942</td>\n",
       "      <td>0.652341</td>\n",
       "      <td>0.780158</td>\n",
       "      <td>10560.718750</td>\n",
       "      <td>1489.918523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.870456</td>\n",
       "      <td>0.930908</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.802894</td>\n",
       "      <td>0.926448</td>\n",
       "      <td>0.897535</td>\n",
       "      <td>10647.679688</td>\n",
       "      <td>1393.638304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.937587</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.938166</td>\n",
       "      <td>0.937586</td>\n",
       "      <td>0.875246</td>\n",
       "      <td>0.938127</td>\n",
       "      <td>0.937528</td>\n",
       "      <td>12868.769531</td>\n",
       "      <td>17377.519214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Average Accuracy  Average Sensitivity  Average Specificity  \\\n",
       "0             LR          0.941433             0.942594             0.940271   \n",
       "1             NB          0.814029             0.839975             0.788083   \n",
       "2            KNN          0.726541             0.970318             0.482765   \n",
       "3  Random Forest          0.900683             0.870456             0.930908   \n",
       "4           LGBM          0.937587             0.937006             0.938166   \n",
       "\n",
       "   Average AUC-ROC  Average MCC  Average Precision  Average F1 Score  \\\n",
       "0         0.941433     0.882895           0.940416          0.941490   \n",
       "1         0.814029     0.628960           0.798547          0.818707   \n",
       "2         0.726541     0.518942           0.652341          0.780158   \n",
       "3         0.900682     0.802894           0.926448          0.897535   \n",
       "4         0.937586     0.875246           0.938127          0.937528   \n",
       "\n",
       "   Memory Used (MB)      Time (s)  \n",
       "0       6615.441406   9456.957862  \n",
       "1      10549.937500    558.072101  \n",
       "2      10560.718750   1489.918523  \n",
       "3      10647.679688   1393.638304  \n",
       "4      12868.769531  17377.519214  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc3aa5-9f81-477b-93c3-f9f1aaba4ef2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
