{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8156597b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 23:09:07.708461: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-18 23:09:07.708536: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-18 23:09:07.711280: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-18 23:09:07.729732: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 23:09:10.106105: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#import required libraries\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
    "from sklearn.metrics import classification_report, roc_auc_score, matthews_corrcoef, precision_score, f1_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, SimpleRNN,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "import keras\n",
    "\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "tf.config.experimental.enable_tensor_float_32_execution(True)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a9bc0f8-8892-44d1-9f4b-d0c89a38ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-tensorrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08f9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "#!pip install imutils\n",
    "#!pip install scikit-learn\n",
    "#!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8016367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to load the dataset images from device\n",
    "\n",
    "class SimpleDatasetLoader:\n",
    "    # Method: Constructor\n",
    "    def __init__(self, preprocessors=None):\n",
    "        \"\"\"\n",
    "        :param preprocessors: List of image preprocessors\n",
    "        \"\"\"\n",
    "        self.preprocessors = preprocessors\n",
    "\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "\n",
    "    # Method: Used to load a list of images for pre-processing\n",
    "    def load(self, image_paths, verbose=-1):\n",
    "        \"\"\"\n",
    "        :param image_paths: List of image paths\n",
    "        :param verbose: Parameter for printing information to console\n",
    "        :return: Tuple of data and labels\n",
    "        \"\"\"\n",
    "        data, labels = [], []\n",
    "\n",
    "        for i, image_path in enumerate(image_paths):\n",
    "            image = cv2.imread(image_path)\n",
    "            label = image_path.split(os.path.sep)[-2]\n",
    "\n",
    "            if self.preprocessors is not None:\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.preprocess(image)\n",
    "\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "            if verbose > 0 and i > 0 and (i+1) % verbose == 0:\n",
    "                print('[INFO]: Processed {}/{}'.format(i+1, len(image_paths)))\n",
    "\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db2af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Preprocessror \n",
    "class SimplePreprocessor:\n",
    "    # Method: Constructor\n",
    "    def __init__(self, width, height, interpolation=cv2.INTER_AREA):\n",
    "        \"\"\"\n",
    "        :param width: Image width\n",
    "        :param height: Image height\n",
    "        :param interpolation: Interpolation algorithm\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    # Method: Used to resize the image to a fixed size (ignoring the aspect ratio)\n",
    "    def preprocess(self, image):\n",
    "        \"\"\"\n",
    "        :param image: Image\n",
    "        :return: Re-sized image\n",
    "        \"\"\"\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11731516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from __main__ import SimplePreprocessor\n",
    "from __main__ import SimpleDatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253976fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Images loading....\n",
      "[INFO]: Processed 1000/2870\n",
      "[INFO]: Processed 2000/2870\n",
      "(2870, 224, 224, 3)\n",
      "(2870,)\n"
     ]
    }
   ],
   "source": [
    "# Function to load and preprocess data using SimpleDatasetLoader\n",
    "def load_and_preprocess_data(image_paths, target_size):\n",
    "    sp = SimplePreprocessor(target_size[0], target_size[1])\n",
    "    sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "    data, labels = sdl.load(image_paths, verbose=1000)\n",
    "\n",
    "    print(data.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "    #labels = to_categorical(labels)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "# Get list of image paths\n",
    "image_paths = list(paths.list_images(\"../BrainTumor/\"))\n",
    "\n",
    "# Define target size for images\n",
    "target_size = (224, 224)  # Change this to your desired size\n",
    "\n",
    "# Load and preprocess data\n",
    "print('[INFO]: Images loading....')\n",
    "data, labels = load_and_preprocess_data(image_paths, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c303fa-776b-4e24-b2fe-58439f2550f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eea8357b-fc36-46ea-a4d9-5eb4c0dda9fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "tf.config.experimental.enable_tensor_float_32_execution(True)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "def calculate_sensitivity_specificity(y_true, y_pred, class_label):\n",
    "    # Create a binary confusion matrix for the specified class\n",
    "    true_positive = sum((y_true == class_label) & (y_pred == class_label))\n",
    "    false_positive = sum((y_true != class_label) & (y_pred == class_label))\n",
    "    true_negative = sum((y_true != class_label) & (y_pred != class_label))\n",
    "    false_negative = sum((y_true == class_label) & (y_pred != class_label))\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    specificity = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
    "\n",
    "    return sensitivity, specificity\n",
    "# Initialize a DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Average Accuracy', 'Average Sensitivity', 'Average Specificity',\n",
    "                                   'Average AUC-ROC', 'Average MCC', 'Average Precision', 'Average F1 Score',\n",
    "                                   'Memory Used (MB)', 'Time (s)'])\n",
    "\n",
    "# Function to evaluate a model\n",
    "def evaluate_model(model, name, data, labels):\n",
    "    accuracy_list = []\n",
    "    sensitivity_list = []\n",
    "    specificity_list = []\n",
    "    auc_roc_list = []\n",
    "    mcc_list = []\n",
    "    precision_list = []\n",
    "    f1_list = []\n",
    "    time_start = time.time()\n",
    "    memory_start = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    if name == \"VGG16\" or name == \"EfficientNetB0\" or name == \"ResNet50\":\n",
    "        with tf.device('/GPU:0'):\n",
    "            tf.random.set_seed(0)\n",
    "            for fold, (train_index, test_index) in enumerate(skf.split(data, labels)):\n",
    "                print(f'\\n[INFO] Fold {fold + 1} / 10 for {name}')\n",
    "\n",
    "                X_train, X_test = data[train_index], data[test_index]\n",
    "                y_train, y_test = to_categorical(labels[train_index]), to_categorical(labels[test_index])\n",
    "\n",
    "                # Adding early stopping to prevent overfitting\n",
    "                early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "                keras.utils.set_random_seed(0)\n",
    "                np.random.seed(0)\n",
    "                tf.random.set_seed(0)\n",
    "                #tf.config.run_functions_eagerly(True)\n",
    "                tf.data.experimental.enable_debug_mode()\n",
    "                # Train the model\n",
    "                # Example of using tf.data.Dataset\n",
    "                #train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                #train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(64)\n",
    "\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(64)\n",
    "\n",
    "                model.fit(train_dataset, epochs=20, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "                # Evaluate the model\n",
    "                predictions = model.predict(X_test)\n",
    "                y_pred = np.argmax(predictions, axis=1)\n",
    "                y_test_encoded = np.argmax(y_test, axis=1)\n",
    "\n",
    "                # print(y_test)\n",
    "                # print(y_test_encoded)\n",
    "                # print(y_pred)\n",
    "                # print(predictions)\n",
    "                # Calculate evaluation metrics for the current fold\n",
    "                # Calculate evaluation metrics for the current fold\n",
    "                accuracy = np.mean(y_pred == y_test_encoded)\n",
    "                sensitivities = []\n",
    "                specificities = []\n",
    "                for class_label in range(num_classes):\n",
    "                    sen, spe = calculate_sensitivity_specificity(y_test_encoded, y_pred, class_label)\n",
    "                    sensitivities.append(sen)\n",
    "                    specificities.append(spe)\n",
    "                sensitivity = sum(sensitivities) / num_classes\n",
    "                specificity = sum(specificities) / num_classes\n",
    "                auc_roc = roc_auc_score(y_test, predictions,multi_class='ovr')\n",
    "                mcc = matthews_corrcoef(y_test_encoded, y_pred)\n",
    "                precision = precision_score(y_test_encoded, y_pred, average='macro')\n",
    "                f1 = f1_score(y_test_encoded, y_pred, average='macro')\n",
    "                # Append metrics to lists\n",
    "                accuracy_list.append(accuracy)\n",
    "                sensitivity_list.append(sensitivity)\n",
    "                specificity_list.append(specificity)\n",
    "                auc_roc_list.append(auc_roc)\n",
    "                mcc_list.append(mcc)\n",
    "                precision_list.append(precision)\n",
    "                f1_list.append(f1)\n",
    "\n",
    "                # Print metrics for the current fold\n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Sensitivity: {sensitivity}\")\n",
    "                print(f\"Specificity: {specificity}\")\n",
    "                print(f\"AUC-ROC: {auc_roc}\")\n",
    "                print(f\"MCC: {mcc}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"F1 Score: {f1}\")\n",
    "                gc.collect()\n",
    "\n",
    "            # Calculate average metrics\n",
    "            average_accuracy = np.mean(accuracy_list)\n",
    "            average_sensitivity = np.mean(sensitivity_list)\n",
    "            average_specificity = np.mean(specificity_list)\n",
    "            average_auc_roc = np.mean(auc_roc_list)\n",
    "            average_mcc = np.mean(mcc_list)\n",
    "            average_precision = np.mean(precision_list)\n",
    "            average_f1 = np.mean(f1_list)\n",
    "\n",
    "            time_end = time.time()\n",
    "            memory_end = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2\n",
    "            del X_train, X_test, y_train, y_test\n",
    "            gc.collect()\n",
    "            tf.keras.backend.clear_session()\n",
    "    else:\n",
    "        data = data.reshape(data.shape[0],data.shape[1] * data.shape[2] * data.shape[3])\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(data, labels)):\n",
    "            print(f'\\n[INFO] Fold {fold + 1} / 10 for {name}')\n",
    "\n",
    "            X_train, X_test = data[train_index], data[test_index]\n",
    "            y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            predictions = model.predict(X_test)\n",
    "            y_prob = model.predict_proba(X_test)\n",
    "            y_pred = predictions\n",
    "            y_test_encoded = y_test\n",
    "\n",
    "            # Calculate evaluation metrics for the current fold\n",
    "            accuracy = np.mean(y_pred == y_test_encoded)\n",
    "            sensitivities = []\n",
    "            specificities = []\n",
    "            for class_label in range(num_classes):\n",
    "                sen, spe = calculate_sensitivity_specificity(y_test, y_pred, class_label)\n",
    "                sensitivities.append(sen)\n",
    "                specificities.append(spe)\n",
    "            sensitivity = sum(sensitivities) / num_classes\n",
    "            specificity = sum(specificities) / num_classes\n",
    "            auc_roc = roc_auc_score(y_test, y_prob,multi_class='ovr')\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            # Append metrics to lists\n",
    "            accuracy_list.append(accuracy)\n",
    "            sensitivity_list.append(sensitivity)\n",
    "            specificity_list.append(specificity)\n",
    "            auc_roc_list.append(auc_roc)\n",
    "            mcc_list.append(mcc)\n",
    "            precision_list.append(precision)\n",
    "            f1_list.append(f1)\n",
    "\n",
    "            # Print metrics for the current fold\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Sensitivity: {sensitivity}\")\n",
    "            print(f\"Specificity: {specificity}\")\n",
    "            print(f\"AUC-ROC: {auc_roc}\")\n",
    "            print(f\"MCC: {mcc}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"F1 Score: {f1}\")\n",
    "            gc.collect()\n",
    "\n",
    "        # Calculate average metrics\n",
    "        average_accuracy = np.mean(accuracy_list)\n",
    "        average_sensitivity = np.mean(sensitivity_list)\n",
    "        average_specificity = np.mean(specificity_list)\n",
    "        average_auc_roc = np.mean(auc_roc_list)\n",
    "        average_mcc = np.mean(mcc_list)\n",
    "        average_precision = np.mean(precision_list)\n",
    "        average_f1 = np.mean(f1_list)\n",
    "\n",
    "        time_end = time.time()\n",
    "        memory_end = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2\n",
    "        \n",
    "\n",
    "    # Append results to DataFrame\n",
    "    results_df.loc[len(results_df)] = [name, average_accuracy, average_sensitivity, average_specificity,\n",
    "                                       average_auc_roc, average_mcc, average_precision, average_f1,\n",
    "                                       memory_end - memory_start, time_end - time_start]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19ae3c9d-9394-4577-9fda-aa508c8f82b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.759581881533101\n",
      "Sensitivity: 0.7503984041230588\n",
      "Specificity: 0.918024154980639\n",
      "AUC-ROC: 0.9144690522055262\n",
      "MCC: 0.6718198287020263\n",
      "Precision: 0.7554306423786157\n",
      "F1 Score: 0.752680715157263\n",
      "\n",
      "[INFO] Fold 2 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7804878048780488\n",
      "Sensitivity: 0.7615273476645795\n",
      "Specificity: 0.9259516591845236\n",
      "AUC-ROC: 0.8806727626760051\n",
      "MCC: 0.70162215751507\n",
      "Precision: 0.7588448907414425\n",
      "F1 Score: 0.7585807581443857\n",
      "\n",
      "[INFO] Fold 3 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7804878048780488\n",
      "Sensitivity: 0.7786285856371076\n",
      "Specificity: 0.9242481217506673\n",
      "AUC-ROC: 0.9217350889606613\n",
      "MCC: 0.7002091537485993\n",
      "Precision: 0.7841848142481054\n",
      "F1 Score: 0.7805137500935944\n",
      "\n",
      "[INFO] Fold 4 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7421602787456446\n",
      "Sensitivity: 0.731939954941718\n",
      "Specificity: 0.9116314543126456\n",
      "AUC-ROC: 0.8919001977662304\n",
      "MCC: 0.6476420175667174\n",
      "Precision: 0.7421400638057014\n",
      "F1 Score: 0.7364336576550701\n",
      "\n",
      "[INFO] Fold 5 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7456445993031359\n",
      "Sensitivity: 0.7418586164545612\n",
      "Specificity: 0.9122285794727016\n",
      "AUC-ROC: 0.9052647330450706\n",
      "MCC: 0.6526998513992005\n",
      "Precision: 0.7483848709430104\n",
      "F1 Score: 0.7435920284567163\n",
      "\n",
      "[INFO] Fold 6 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794425087108014\n",
      "Sensitivity: 0.7786897590361446\n",
      "Specificity: 0.9300686429405376\n",
      "AUC-ROC: 0.9158176951826483\n",
      "MCC: 0.7204326459496414\n",
      "Precision: 0.7836308030273548\n",
      "F1 Score: 0.7794830806731521\n",
      "\n",
      "[INFO] Fold 7 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.759581881533101\n",
      "Sensitivity: 0.7482019541580958\n",
      "Specificity: 0.9176721325441404\n",
      "AUC-ROC: 0.9049488761445822\n",
      "MCC: 0.6715274976904175\n",
      "Precision: 0.7568463018267055\n",
      "F1 Score: 0.7519521770484544\n",
      "\n",
      "[INFO] Fold 8 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7491289198606271\n",
      "Sensitivity: 0.74946738172201\n",
      "Specificity: 0.9141312923905613\n",
      "AUC-ROC: 0.9085211534130704\n",
      "MCC: 0.6583133588437874\n",
      "Precision: 0.7464733848500035\n",
      "F1 Score: 0.7476593595144013\n",
      "\n",
      "[INFO] Fold 9 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794425087108014\n",
      "Sensitivity: 0.7888811342932707\n",
      "Specificity: 0.9294046975954399\n",
      "AUC-ROC: 0.9183370963579172\n",
      "MCC: 0.7196826000866425\n",
      "Precision: 0.7977951102951103\n",
      "F1 Score: 0.7925962860976573\n",
      "\n",
      "[INFO] Fold 10 / 10 for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.759581881533101\n",
      "Sensitivity: 0.7327101087275933\n",
      "Specificity: 0.9175705065278802\n",
      "AUC-ROC: 0.9122886934503993\n",
      "MCC: 0.6709814390469694\n",
      "Precision: 0.7506054884507642\n",
      "F1 Score: 0.7387631180146941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# LR\n",
    "lr_model = LogisticRegression(n_jobs=-1, random_state=0)\n",
    "evaluate_model(lr_model, 'LR', data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "743d006a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for NB\n",
      "Accuracy: 0.578397212543554\n",
      "Sensitivity: 0.5478320411100311\n",
      "Specificity: 0.8540035250921768\n",
      "AUC-ROC: 0.700917783101104\n",
      "MCC: 0.44868139198977697\n",
      "Precision: 0.5380835543766579\n",
      "F1 Score: 0.5095498237444716\n",
      "\n",
      "[INFO] Fold 2 / 10 for NB\n",
      "Accuracy: 0.5679442508710801\n",
      "Sensitivity: 0.5591116812465622\n",
      "Specificity: 0.8529361626633345\n",
      "AUC-ROC: 0.7048787702595288\n",
      "MCC: 0.43814451701795426\n",
      "Precision: 0.5061128035606257\n",
      "F1 Score: 0.5086769159096203\n",
      "\n",
      "[INFO] Fold 3 / 10 for NB\n",
      "Accuracy: 0.6167247386759582\n",
      "Sensitivity: 0.6150935825855015\n",
      "Specificity: 0.8674360932413878\n",
      "AUC-ROC: 0.7443407270780434\n",
      "MCC: 0.5025102764229787\n",
      "Precision: 0.6186002178649238\n",
      "F1 Score: 0.5789359541798015\n",
      "\n",
      "[INFO] Fold 4 / 10 for NB\n",
      "Accuracy: 0.6027874564459931\n",
      "Sensitivity: 0.5918034238266386\n",
      "Specificity: 0.862669408833557\n",
      "AUC-ROC: 0.7261142807288694\n",
      "MCC: 0.4870609714915547\n",
      "Precision: 0.5750333166749958\n",
      "F1 Score: 0.550478241478131\n",
      "\n",
      "[INFO] Fold 5 / 10 for NB\n",
      "Accuracy: 0.6306620209059234\n",
      "Sensitivity: 0.6228431549839131\n",
      "Specificity: 0.8733310771200691\n",
      "AUC-ROC: 0.7476477033141913\n",
      "MCC: 0.5333457027829145\n",
      "Precision: 0.6163130001082441\n",
      "F1 Score: 0.5753145502745376\n",
      "\n",
      "[INFO] Fold 6 / 10 for NB\n",
      "Accuracy: 0.5818815331010453\n",
      "Sensitivity: 0.5708198648251543\n",
      "Specificity: 0.8566674072611171\n",
      "AUC-ROC: 0.7134905996058888\n",
      "MCC: 0.46765349277694723\n",
      "Precision: 0.5583315554417705\n",
      "F1 Score: 0.5215147868347709\n",
      "\n",
      "[INFO] Fold 7 / 10 for NB\n",
      "Accuracy: 0.6445993031358885\n",
      "Sensitivity: 0.6382089332941523\n",
      "Specificity: 0.8781979158800876\n",
      "AUC-ROC: 0.761027889251733\n",
      "MCC: 0.5417593286684654\n",
      "Precision: 0.6289532069382815\n",
      "F1 Score: 0.6000477525043999\n",
      "\n",
      "[INFO] Fold 8 / 10 for NB\n",
      "Accuracy: 0.6062717770034843\n",
      "Sensitivity: 0.5949584925066118\n",
      "Specificity: 0.8640636707926974\n",
      "AUC-ROC: 0.7322887022100015\n",
      "MCC: 0.4885656088936976\n",
      "Precision: 0.5892443783068784\n",
      "F1 Score: 0.5617224079602572\n",
      "\n",
      "[INFO] Fold 9 / 10 for NB\n",
      "Accuracy: 0.5993031358885017\n",
      "Sensitivity: 0.6048670290919778\n",
      "Specificity: 0.8624242221822075\n",
      "AUC-ROC: 0.7336456256370926\n",
      "MCC: 0.4865858086475789\n",
      "Precision: 0.6066434316343574\n",
      "F1 Score: 0.5668204028836213\n",
      "\n",
      "[INFO] Fold 10 / 10 for NB\n",
      "Accuracy: 0.5923344947735192\n",
      "Sensitivity: 0.5827266382603584\n",
      "Specificity: 0.8595943769035214\n",
      "AUC-ROC: 0.7206028038341707\n",
      "MCC: 0.4737332939030814\n",
      "Precision: 0.5617039234210452\n",
      "F1 Score: 0.537410754200258\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "#svm_model = SVC(probability=True)\n",
    "#evaluate_model(svm_model, 'SVM', data, labels)\n",
    "\n",
    "\n",
    "#NB\n",
    "nb_model = GaussianNB()\n",
    "evaluate_model(nb_model, 'NB', data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04aacd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for KNN\n",
      "Accuracy: 0.7979094076655052\n",
      "Sensitivity: 0.7900702246132748\n",
      "Specificity: 0.9302859027167123\n",
      "AUC-ROC: 0.9523923085754715\n",
      "MCC: 0.7293654897870671\n",
      "Precision: 0.8068053663138036\n",
      "F1 Score: 0.7900845294148989\n",
      "\n",
      "[INFO] Fold 2 / 10 for KNN\n",
      "Accuracy: 0.8153310104529616\n",
      "Sensitivity: 0.7983707814371934\n",
      "Specificity: 0.9381288471328737\n",
      "AUC-ROC: 0.9423030602090307\n",
      "MCC: 0.7551295985035361\n",
      "Precision: 0.8026529482216515\n",
      "F1 Score: 0.7907525113598216\n",
      "\n",
      "[INFO] Fold 3 / 10 for KNN\n",
      "Accuracy: 0.8083623693379791\n",
      "Sensitivity: 0.8025413097041072\n",
      "Specificity: 0.9337449476249982\n",
      "AUC-ROC: 0.9390395103361894\n",
      "MCC: 0.7434781823428044\n",
      "Precision: 0.8197550628049435\n",
      "F1 Score: 0.8032628101869546\n",
      "\n",
      "[INFO] Fold 4 / 10 for KNN\n",
      "Accuracy: 0.794425087108014\n",
      "Sensitivity: 0.7812902642464794\n",
      "Specificity: 0.9292098625445457\n",
      "AUC-ROC: 0.9404079679483864\n",
      "MCC: 0.727866717970588\n",
      "Precision: 0.8086011626403303\n",
      "F1 Score: 0.7830175653362181\n",
      "\n",
      "[INFO] Fold 5 / 10 for KNN\n",
      "Accuracy: 0.7560975609756098\n",
      "Sensitivity: 0.731129960743537\n",
      "Specificity: 0.9164116374323137\n",
      "AUC-ROC: 0.9353568546498987\n",
      "MCC: 0.6780867510554028\n",
      "Precision: 0.7630118527074224\n",
      "F1 Score: 0.7296481310141041\n",
      "\n",
      "[INFO] Fold 6 / 10 for KNN\n",
      "Accuracy: 0.8153310104529616\n",
      "Sensitivity: 0.7904698060534823\n",
      "Specificity: 0.9369171812103927\n",
      "AUC-ROC: 0.9368906317138904\n",
      "MCC: 0.7562304464273061\n",
      "Precision: 0.8184901823515685\n",
      "F1 Score: 0.7906986327499267\n",
      "\n",
      "[INFO] Fold 7 / 10 for KNN\n",
      "Accuracy: 0.7770034843205574\n",
      "Sensitivity: 0.7601711724948574\n",
      "Specificity: 0.9241425804053229\n",
      "AUC-ROC: 0.9415838988156776\n",
      "MCC: 0.704160263074367\n",
      "Precision: 0.7701639033396825\n",
      "F1 Score: 0.7529693905679148\n",
      "\n",
      "[INFO] Fold 8 / 10 for KNN\n",
      "Accuracy: 0.8327526132404182\n",
      "Sensitivity: 0.8219401998236849\n",
      "Specificity: 0.9432101526302236\n",
      "AUC-ROC: 0.9627127073872063\n",
      "MCC: 0.7748622122501713\n",
      "Precision: 0.8236359035701141\n",
      "F1 Score: 0.8190549779860743\n",
      "\n",
      "[INFO] Fold 9 / 10 for KNN\n",
      "Accuracy: 0.8083623693379791\n",
      "Sensitivity: 0.7973607846018219\n",
      "Specificity: 0.935449231040298\n",
      "AUC-ROC: 0.9376134922742997\n",
      "MCC: 0.7466624280876787\n",
      "Precision: 0.8025019098548511\n",
      "F1 Score: 0.7900107326663118\n",
      "\n",
      "[INFO] Fold 10 / 10 for KNN\n",
      "Accuracy: 0.8222996515679443\n",
      "Sensitivity: 0.8030065383485161\n",
      "Specificity: 0.9397290924862094\n",
      "AUC-ROC: 0.9533471963216125\n",
      "MCC: 0.766394373038951\n",
      "Precision: 0.8214320027281471\n",
      "F1 Score: 0.7994571717242296\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KNN\n",
    "knn_model = KNeighborsClassifier()\n",
    "evaluate_model(knn_model, 'KNN', data, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46ce2ad5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for Random Forest\n",
      "Accuracy: 0.8989547038327527\n",
      "Sensitivity: 0.9021621193969122\n",
      "Specificity: 0.9662958377686244\n",
      "AUC-ROC: 0.9866227540070278\n",
      "MCC: 0.8646398650901709\n",
      "Precision: 0.8945730597904511\n",
      "F1 Score: 0.8951889175594337\n",
      "\n",
      "[INFO] Fold 2 / 10 for Random Forest\n",
      "Accuracy: 0.89198606271777\n",
      "Sensitivity: 0.8991321759834837\n",
      "Specificity: 0.9653309691303744\n",
      "AUC-ROC: 0.9849897460250068\n",
      "MCC: 0.855889683620612\n",
      "Precision: 0.8750940839981937\n",
      "F1 Score: 0.8819567344665815\n",
      "\n",
      "[INFO] Fold 3 / 10 for Random Forest\n",
      "Accuracy: 0.867595818815331\n",
      "Sensitivity: 0.8544440425868578\n",
      "Specificity: 0.9559246810447232\n",
      "AUC-ROC: 0.9801397469882283\n",
      "MCC: 0.820131397883858\n",
      "Precision: 0.8530043486481376\n",
      "F1 Score: 0.8528747033683363\n",
      "\n",
      "[INFO] Fold 4 / 10 for Random Forest\n",
      "Accuracy: 0.8850174216027874\n",
      "Sensitivity: 0.8830603841256206\n",
      "Specificity: 0.9606579079310718\n",
      "AUC-ROC: 0.9839696386883388\n",
      "MCC: 0.8450832374237696\n",
      "Precision: 0.8898637929518922\n",
      "F1 Score: 0.883961618226126\n",
      "\n",
      "[INFO] Fold 5 / 10 for Random Forest\n",
      "Accuracy: 0.8780487804878049\n",
      "Sensitivity: 0.8804344959575638\n",
      "Specificity: 0.958871160580676\n",
      "AUC-ROC: 0.9847298061407272\n",
      "MCC: 0.835198630468901\n",
      "Precision: 0.8741283166291538\n",
      "F1 Score: 0.8753782126892101\n",
      "\n",
      "[INFO] Fold 6 / 10 for Random Forest\n",
      "Accuracy: 0.9163763066202091\n",
      "Sensitivity: 0.9172990743461652\n",
      "Specificity: 0.9725740933284541\n",
      "AUC-ROC: 0.9871097161968311\n",
      "MCC: 0.8870802834945843\n",
      "Precision: 0.9039604085341231\n",
      "F1 Score: 0.9091881764644497\n",
      "\n",
      "[INFO] Fold 7 / 10 for Random Forest\n",
      "Accuracy: 0.8989547038327527\n",
      "Sensitivity: 0.908457610931531\n",
      "Specificity: 0.9666898767999349\n",
      "AUC-ROC: 0.9795457172800213\n",
      "MCC: 0.8645879145346183\n",
      "Precision: 0.8913491707560337\n",
      "F1 Score: 0.8964348696506326\n",
      "\n",
      "[INFO] Fold 8 / 10 for Random Forest\n",
      "Accuracy: 0.9059233449477352\n",
      "Sensitivity: 0.9117212753452836\n",
      "Specificity: 0.9676773360672402\n",
      "AUC-ROC: 0.9830906265236599\n",
      "MCC: 0.8728338319557053\n",
      "Precision: 0.9099436453196519\n",
      "F1 Score: 0.9096458683004666\n",
      "\n",
      "[INFO] Fold 9 / 10 for Random Forest\n",
      "Accuracy: 0.8885017421602788\n",
      "Sensitivity: 0.8901851307669703\n",
      "Specificity: 0.9626225853232574\n",
      "AUC-ROC: 0.9782103360381529\n",
      "MCC: 0.8504880131414241\n",
      "Precision: 0.8868819318094681\n",
      "F1 Score: 0.8857357765756327\n",
      "\n",
      "[INFO] Fold 10 / 10 for Random Forest\n",
      "Accuracy: 0.9094076655052264\n",
      "Sensitivity: 0.9082574199235968\n",
      "Specificity: 0.9697263140468985\n",
      "AUC-ROC: 0.9845380355117026\n",
      "MCC: 0.8771838689798717\n",
      "Precision: 0.9013195981223407\n",
      "F1 Score: 0.9041018425974967\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "evaluate_model(rf_model, 'Random Forest', data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaa8cf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for LGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 29.796524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21000372\n",
      "[LightGBM] [Info] Number of data points in the train set: 2583, number of used features: 150528\n",
      "[LightGBM] [Info] Start training from score -1.246011\n",
      "[LightGBM] [Info] Start training from score -1.250057\n",
      "[LightGBM] [Info] Start training from score -1.981776\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9059233449477352\n",
      "Sensitivity: 0.9081494834874208\n",
      "Specificity: 0.9683059887999259\n",
      "AUC-ROC: 0.9889542034787013\n",
      "MCC: 0.8731108181105262\n",
      "Precision: 0.9029629275952806\n",
      "F1 Score: 0.9038059847594953\n",
      "\n",
      "[INFO] Fold 2 / 10 for LGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 29.925221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20866698\n",
      "[LightGBM] [Info] Number of data points in the train set: 2583, number of used features: 150528\n",
      "[LightGBM] [Info] Start training from score -1.246011\n",
      "[LightGBM] [Info] Start training from score -1.250057\n",
      "[LightGBM] [Info] Start training from score -1.981776\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9059233449477352\n",
      "Sensitivity: 0.9179400528945049\n",
      "Specificity: 0.969768188550007\n",
      "AUC-ROC: 0.9830529222005003\n",
      "MCC: 0.8756842397679454\n",
      "Precision: 0.8921132779099398\n",
      "F1 Score: 0.8983480123387196\n",
      "\n",
      "[INFO] Fold 3 / 10 for LGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 29.947378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20921418\n",
      "[LightGBM] [Info] Number of data points in the train set: 2583, number of used features: 150528\n",
      "[LightGBM] [Info] Start training from score -1.246011\n",
      "[LightGBM] [Info] Start training from score -1.250057\n",
      "[LightGBM] [Info] Start training from score -1.981776\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9128919860627178\n",
      "Sensitivity: 0.9141001152828953\n",
      "Specificity: 0.9709385268662933\n",
      "AUC-ROC: 0.9869682631248222\n",
      "MCC: 0.8818401716471326\n",
      "Precision: 0.9041200805008944\n",
      "F1 Score: 0.9082536427820166\n",
      "\n",
      "[INFO] Fold 4 / 10 for LGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 29.957107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21002244\n",
      "[LightGBM] [Info] Number of data points in the train set: 2583, number of used features: 150528\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Info] Start training from score -1.251409\n",
      "[LightGBM] [Info] Start training from score -1.981776\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.89198606271777\n",
      "Sensitivity: 0.8858332014738127\n",
      "Specificity: 0.9631088883232286\n",
      "AUC-ROC: 0.9864665309293782\n",
      "MCC: 0.8533872749691276\n",
      "Precision: 0.8923881965719018\n",
      "F1 Score: 0.8879144155786847\n",
      "\n",
      "[INFO] Fold 5 / 10 for LGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 30.085369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20948325\n",
      "[LightGBM] [Info] Number of data points in the train set: 2583, number of used features: 150528\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Info] Start training from score -1.251409\n",
      "[LightGBM] [Info] Start training from score -1.981776\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.8885017421602788\n",
      "Sensitivity: 0.8861826292034931\n",
      "Specificity: 0.9623302054889619\n",
      "AUC-ROC: 0.9869926211240857\n",
      "MCC: 0.8486726784703523\n",
      "Precision: 0.8836033432070016\n",
      "F1 Score: 0.8839822716240933\n",
      "\n",
      "[INFO] Fold 6 / 10 for LGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 29.742762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20934258\n",
      "[LightGBM] [Info] Number of data points in the train set: 2583, number of used features: 150528\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Info] Start training from score -1.250057\n",
      "[LightGBM] [Info] Start training from score -1.984589\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9128919860627178\n",
      "Sensitivity: 0.9174882456655892\n",
      "Specificity: 0.9715559695785098\n",
      "AUC-ROC: 0.9868965372924621\n",
      "MCC: 0.8828481962306914\n",
      "Precision: 0.9005525564656243\n",
      "F1 Score: 0.9066688065926505\n",
      "\n",
      "[INFO] Fold 7 / 10 for LGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 29.678490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20896860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2583, number of used features: 150528\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Info] Start training from score -1.250057\n",
      "[LightGBM] [Info] Start training from score -1.984589\n",
      "[LightGBM] [Info] Start training from score -1.244666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9163763066202091\n",
      "Sensitivity: 0.9237015133705554\n",
      "Specificity: 0.9727934157765011\n",
      "AUC-ROC: 0.9856807950192261\n",
      "MCC: 0.8877188607975607\n",
      "Precision: 0.9052471621178592\n",
      "F1 Score: 0.9117087799818436\n",
      "\n",
      "[INFO] Fold 8 / 10 for LGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 29.803217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20914302\n",
      "[LightGBM] [Info] Number of data points in the train set: 2583, number of used features: 150528\n",
      "[LightGBM] [Info] Start training from score -1.246011\n",
      "[LightGBM] [Info] Start training from score -1.250057\n",
      "[LightGBM] [Info] Start training from score -1.984589\n",
      "[LightGBM] [Info] Start training from score -1.243323\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9128919860627178\n",
      "Sensitivity: 0.9176351748457243\n",
      "Specificity: 0.9703117709017052\n",
      "AUC-ROC: 0.9888143927308628\n",
      "MCC: 0.8816302590689672\n",
      "Precision: 0.9114657489812614\n",
      "F1 Score: 0.9142272945398401\n",
      "\n",
      "[INFO] Fold 9 / 10 for LGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 30.232040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20902644\n",
      "[LightGBM] [Info] Number of data points in the train set: 2583, number of used features: 150528\n",
      "[LightGBM] [Info] Start training from score -1.246011\n",
      "[LightGBM] [Info] Start training from score -1.250057\n",
      "[LightGBM] [Info] Start training from score -1.984589\n",
      "[LightGBM] [Info] Start training from score -1.243323\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9059233449477352\n",
      "Sensitivity: 0.9052453717308258\n",
      "Specificity: 0.9689275127450012\n",
      "AUC-ROC: 0.9836784897816468\n",
      "MCC: 0.872914056916547\n",
      "Precision: 0.8952481353987378\n",
      "F1 Score: 0.898874479845871\n",
      "\n",
      "[INFO] Fold 10 / 10 for LGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 29.648125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20955315\n",
      "[LightGBM] [Info] Number of data points in the train set: 2583, number of used features: 150528\n",
      "[LightGBM] [Info] Start training from score -1.246011\n",
      "[LightGBM] [Info] Start training from score -1.250057\n",
      "[LightGBM] [Info] Start training from score -1.984589\n",
      "[LightGBM] [Info] Start training from score -1.243323\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9233449477351916\n",
      "Sensitivity: 0.9235435645019101\n",
      "Specificity: 0.9748236852754334\n",
      "AUC-ROC: 0.9899644256687028\n",
      "MCC: 0.8963958597843181\n",
      "Precision: 0.9123280893012837\n",
      "F1 Score: 0.9167953460999083\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "# LGBM\n",
    "lgb_model = lightgbm.LGBMClassifier(random_state=0, n_jobs = -1)\n",
    "evaluate_model(lgb_model, 'LGBM', data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b354e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 05:14:56.282140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8447 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:65:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for VGG16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 05:14:58.406950: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 05:15:03.540223: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-03-19 05:15:03.853458: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-19 05:15:07.026338: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f43eb720e80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-19 05:15:07.026399: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-03-19 05:15:07.041914: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710825307.351275  956491 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 9s 54ms/step - loss: 9.1348 - accuracy: 0.6860\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.6287 - accuracy: 0.8076\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.4398 - accuracy: 0.8405\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.3681 - accuracy: 0.8606\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.3157 - accuracy: 0.8839\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.2320 - accuracy: 0.9110\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.2061 - accuracy: 0.9210\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.2024 - accuracy: 0.9319\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.2288 - accuracy: 0.9187\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.2322 - accuracy: 0.9175\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.2024 - accuracy: 0.9292\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1698 - accuracy: 0.9311\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1574 - accuracy: 0.9473\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1336 - accuracy: 0.9462\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1270 - accuracy: 0.9481\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.1353 - accuracy: 0.9535\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1205 - accuracy: 0.9539\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.1353 - accuracy: 0.9512\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1497 - accuracy: 0.9489\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.1302 - accuracy: 0.9501\n",
      "9/9 [==============================] - 1s 46ms/step\n",
      "Accuracy: 0.9337979094076655\n",
      "Sensitivity: 0.9358277387222437\n",
      "Specificity: 0.9772402076487559\n",
      "AUC-ROC: 0.9963946495850811\n",
      "MCC: 0.9114830258958123\n",
      "Precision: 0.9408328101487838\n",
      "F1 Score: 0.9362705981672169\n",
      "\n",
      "[INFO] Fold 2 / 10 for VGG16\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.1536 - accuracy: 0.9450\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.1593 - accuracy: 0.9443\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1465 - accuracy: 0.9477\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1436 - accuracy: 0.9539\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.1554 - accuracy: 0.9462\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.1984 - accuracy: 0.9419\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.1451 - accuracy: 0.9473\n",
      "9/9 [==============================] - 0s 25ms/step\n",
      "Accuracy: 0.9895470383275261\n",
      "Sensitivity: 0.9908536585365854\n",
      "Specificity: 0.9963235294117647\n",
      "AUC-ROC: 0.9990653080179486\n",
      "MCC: 0.985845943001911\n",
      "Precision: 0.9911414565826331\n",
      "F1 Score: 0.9908684184426179\n",
      "\n",
      "[INFO] Fold 3 / 10 for VGG16\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.1468 - accuracy: 0.9551\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.1304 - accuracy: 0.9493\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1285 - accuracy: 0.9532\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1090 - accuracy: 0.9624\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1376 - accuracy: 0.9501\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1564 - accuracy: 0.9473\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1081 - accuracy: 0.9617\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1209 - accuracy: 0.9590\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0961 - accuracy: 0.9624\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0850 - accuracy: 0.9644\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0951 - accuracy: 0.9644\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1000 - accuracy: 0.9621\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.1342 - accuracy: 0.9574\n",
      "9/9 [==============================] - 0s 26ms/step\n",
      "Accuracy: 0.9930313588850174\n",
      "Sensitivity: 0.9939759036144579\n",
      "Specificity: 0.9975609756097561\n",
      "AUC-ROC: 0.9999109817159951\n",
      "MCC: 0.9905541567153362\n",
      "Precision: 0.9940476190476191\n",
      "F1 Score: 0.993939171319424\n",
      "\n",
      "[INFO] Fold 4 / 10 for VGG16\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.0913 - accuracy: 0.9590\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1463 - accuracy: 0.9617\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1006 - accuracy: 0.9593\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.1603 - accuracy: 0.9439\n",
      "9/9 [==============================] - 0s 28ms/step\n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "AUC-ROC: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "[INFO] Fold 5 / 10 for VGG16\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.0928 - accuracy: 0.9675\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1171 - accuracy: 0.9574\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1364 - accuracy: 0.9504\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.1476 - accuracy: 0.9493\n",
      "9/9 [==============================] - 0s 27ms/step\n",
      "Accuracy: 0.9965156794425087\n",
      "Sensitivity: 0.9969879518072289\n",
      "Specificity: 0.9987745098039216\n",
      "AUC-ROC: 1.0\n",
      "MCC: 0.9952605851064119\n",
      "Precision: 0.9970238095238095\n",
      "F1 Score: 0.9969878424968246\n",
      "\n",
      "[INFO] Fold 6 / 10 for VGG16\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.0784 - accuracy: 0.9698\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0926 - accuracy: 0.9644\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1003 - accuracy: 0.9593\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.1013 - accuracy: 0.9605\n",
      "9/9 [==============================] - 1s 26ms/step\n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "AUC-ROC: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "[INFO] Fold 7 / 10 for VGG16\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.0894 - accuracy: 0.9636\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0837 - accuracy: 0.9683\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1113 - accuracy: 0.9590\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0912 - accuracy: 0.9721\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.1706 - accuracy: 0.9512\n",
      "9/9 [==============================] - 0s 25ms/step\n",
      "Accuracy: 0.9965156794425087\n",
      "Sensitivity: 0.9969879518072289\n",
      "Specificity: 0.998780487804878\n",
      "AUC-ROC: 1.0\n",
      "MCC: 0.9952674079957639\n",
      "Precision: 0.9969879518072289\n",
      "F1 Score: 0.9969696969696971\n",
      "\n",
      "[INFO] Fold 8 / 10 for VGG16\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.1170 - accuracy: 0.9628\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0983 - accuracy: 0.9698\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1305 - accuracy: 0.9532\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1068 - accuracy: 0.9648\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.1297 - accuracy: 0.9551\n",
      "9/9 [==============================] - 0s 25ms/step\n",
      "Accuracy: 0.9965156794425087\n",
      "Sensitivity: 0.9969512195121951\n",
      "Specificity: 0.998780487804878\n",
      "AUC-ROC: 1.0\n",
      "MCC: 0.9952673298180527\n",
      "Precision: 0.9969879518072289\n",
      "F1 Score: 0.9969511061535602\n",
      "\n",
      "[INFO] Fold 9 / 10 for VGG16\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.1296 - accuracy: 0.9528\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.1063 - accuracy: 0.9601\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1337 - accuracy: 0.9481\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1401 - accuracy: 0.9501\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.1352 - accuracy: 0.9539\n",
      "9/9 [==============================] - 1s 27ms/step\n",
      "Accuracy: 0.9965156794425087\n",
      "Sensitivity: 0.9969512195121951\n",
      "Specificity: 0.9987745098039216\n",
      "AUC-ROC: 0.9999851279000596\n",
      "MCC: 0.9952672519103013\n",
      "Precision: 0.9970238095238095\n",
      "F1 Score: 0.9969692516806877\n",
      "\n",
      "[INFO] Fold 10 / 10 for VGG16\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.0976 - accuracy: 0.9605\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.0877 - accuracy: 0.9675\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1265 - accuracy: 0.9617\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1731 - accuracy: 0.9489\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.1777 - accuracy: 0.9454\n",
      "9/9 [==============================] - 0s 27ms/step\n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "AUC-ROC: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Load the VGG16 model pre-trained on ImageNet data\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build a new model using VGG16 as a feature extractor\n",
    "with tf.device('/GPU:0'):\n",
    "    model_vgg16 = Sequential()\n",
    "    model_vgg16.add(vgg16_model)\n",
    "    model_vgg16.add(Flatten())\n",
    "    model_vgg16.add(Dense(256, activation='relu', kernel_initializer='glorot_normal', bias_initializer='zeros'))\n",
    "    model_vgg16.add(Dropout(0.5, seed = 0))\n",
    "    model_vgg16.add(Dense(num_classes, activation='softmax', kernel_initializer='glorot_normal', bias_initializer='zeros'))\n",
    "\n",
    "    # Compile the model\n",
    "    model_vgg16.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    evaluate_model(model_vgg16, 'VGG16', data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1798333-1f2f-4c56-810d-7c319a046435",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for EfficientNetB0\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 19s 53ms/step - loss: 3.9943 - accuracy: 0.6411\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.5364 - accuracy: 0.7755\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.4177 - accuracy: 0.8250\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.3608 - accuracy: 0.8432\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.2974 - accuracy: 0.8908\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.3105 - accuracy: 0.8719\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.2593 - accuracy: 0.8862\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.2349 - accuracy: 0.8955\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.2274 - accuracy: 0.9032\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.2111 - accuracy: 0.9164\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.2162 - accuracy: 0.9082\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.1842 - accuracy: 0.9168\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.1690 - accuracy: 0.9191\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.1506 - accuracy: 0.9342\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.1695 - accuracy: 0.9261\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.1856 - accuracy: 0.9222\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.1577 - accuracy: 0.9292\n",
      "9/9 [==============================] - 4s 38ms/step\n",
      "Accuracy: 0.9581881533101045\n",
      "Sensitivity: 0.9635982956215103\n",
      "Specificity: 0.9861937103716388\n",
      "AUC-ROC: 0.9963534692358009\n",
      "MCC: 0.943330254982352\n",
      "Precision: 0.9520418050941307\n",
      "F1 Score: 0.9571266299097485\n",
      "\n",
      "[INFO] Fold 2 / 10 for EfficientNetB0\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 53ms/step - loss: 0.1922 - accuracy: 0.9202\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.2123 - accuracy: 0.9164\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.2110 - accuracy: 0.9199\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.1964 - accuracy: 0.9125\n",
      "9/9 [==============================] - 1s 27ms/step\n",
      "Accuracy: 0.9825783972125436\n",
      "Sensitivity: 0.9814313539335578\n",
      "Specificity: 0.9938845050215208\n",
      "AUC-ROC: 0.9993730461404361\n",
      "MCC: 0.9762515946034414\n",
      "Precision: 0.9849327593598796\n",
      "F1 Score: 0.9830962964278435\n",
      "\n",
      "[INFO] Fold 3 / 10 for EfficientNetB0\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 52ms/step - loss: 0.1724 - accuracy: 0.9249\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.1915 - accuracy: 0.9210\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.1972 - accuracy: 0.9144\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.1854 - accuracy: 0.9249\n",
      "9/9 [==============================] - 1s 24ms/step\n",
      "Accuracy: 0.9895470383275261\n",
      "Sensitivity: 0.9908903908316191\n",
      "Specificity: 0.9965409550917141\n",
      "AUC-ROC: 0.9999852350578786\n",
      "MCC: 0.9858240096595807\n",
      "Precision: 0.9878676470588236\n",
      "F1 Score: 0.9892576812935463\n",
      "\n",
      "[INFO] Fold 4 / 10 for EfficientNetB0\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 53ms/step - loss: 0.1554 - accuracy: 0.9357\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.1789 - accuracy: 0.9268\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.1671 - accuracy: 0.9326\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 51ms/step - loss: 0.1806 - accuracy: 0.9230\n",
      "9/9 [==============================] - 2s 26ms/step\n",
      "Accuracy: 0.9825783972125436\n",
      "Sensitivity: 0.9847928298560094\n",
      "Specificity: 0.9938725490196079\n",
      "AUC-ROC: 0.9995261288004662\n",
      "MCC: 0.9765588279235675\n",
      "Precision: 0.9857954545454546\n",
      "F1 Score: 0.9849249069643806\n",
      "\n",
      "[INFO] Fold 5 / 10 for EfficientNetB0\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 53ms/step - loss: 0.1592 - accuracy: 0.9357\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.2018 - accuracy: 0.9133\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.1905 - accuracy: 0.9292\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.1821 - accuracy: 0.9237\n",
      "9/9 [==============================] - 1s 23ms/step\n",
      "Accuracy: 0.9895470383275261\n",
      "Sensitivity: 0.9908903908316191\n",
      "Specificity: 0.9963295074127212\n",
      "AUC-ROC: 0.9998666868896309\n",
      "MCC: 0.9857483765191397\n",
      "Precision: 0.9909611992945326\n",
      "F1 Score: 0.9909077550420631\n",
      "\n",
      "[INFO] Fold 6 / 10 for EfficientNetB0\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 53ms/step - loss: 0.1437 - accuracy: 0.9439\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.2004 - accuracy: 0.9191\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.2083 - accuracy: 0.9214\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.1710 - accuracy: 0.9307\n",
      "9/9 [==============================] - 1s 24ms/step\n",
      "Accuracy: 0.9930313588850174\n",
      "Sensitivity: 0.9939024390243902\n",
      "Specificity: 0.9977683420558902\n",
      "AUC-ROC: 0.9999553837001784\n",
      "MCC: 0.9905249246287513\n",
      "Precision: 0.9908536585365854\n",
      "F1 Score: 0.9923310574278204\n",
      "\n",
      "[INFO] Fold 7 / 10 for EfficientNetB0\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 53ms/step - loss: 0.1435 - accuracy: 0.9470\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.2534 - accuracy: 0.9017\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.2068 - accuracy: 0.9202\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.2035 - accuracy: 0.9191\n",
      "9/9 [==============================] - 1s 24ms/step\n",
      "Accuracy: 0.9860627177700348\n",
      "Sensitivity: 0.9878416103438142\n",
      "Specificity: 0.9951219512195122\n",
      "AUC-ROC: 0.9998810232004759\n",
      "MCC: 0.9811174046314529\n",
      "Precision: 0.9880514705882353\n",
      "F1 Score: 0.9878209910146039\n",
      "\n",
      "[INFO] Fold 8 / 10 for EfficientNetB0\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 53ms/step - loss: 0.1725 - accuracy: 0.9357\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.2377 - accuracy: 0.9032\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.2509 - accuracy: 0.9067\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.2089 - accuracy: 0.9183\n",
      "9/9 [==============================] - 1s 25ms/step\n",
      "Accuracy: 0.9895470383275261\n",
      "Sensitivity: 0.987689171319424\n",
      "Specificity: 0.9963354854136777\n",
      "AUC-ROC: 0.9997923263899282\n",
      "MCC: 0.9857592457412532\n",
      "Precision: 0.9909638554216867\n",
      "F1 Score: 0.989277940299749\n",
      "\n",
      "[INFO] Fold 9 / 10 for EfficientNetB0\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 53ms/step - loss: 0.1643 - accuracy: 0.9381\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.1813 - accuracy: 0.9311\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.2007 - accuracy: 0.9253\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.2162 - accuracy: 0.9210\n",
      "9/9 [==============================] - 1s 24ms/step\n",
      "Accuracy: 0.9965156794425087\n",
      "Sensitivity: 0.9969879518072289\n",
      "Specificity: 0.998780487804878\n",
      "AUC-ROC: 1.0\n",
      "MCC: 0.9952674079957639\n",
      "Precision: 0.9969879518072289\n",
      "F1 Score: 0.9969696969696971\n",
      "\n",
      "[INFO] Fold 10 / 10 for EfficientNetB0\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 53ms/step - loss: 0.1309 - accuracy: 0.9512\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.1782 - accuracy: 0.9326\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.1665 - accuracy: 0.9377\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.2103 - accuracy: 0.9202\n",
      "9/9 [==============================] - 1s 25ms/step\n",
      "Accuracy: 0.9895470383275261\n",
      "Sensitivity: 0.990927123126653\n",
      "Specificity: 0.9963414634146341\n",
      "AUC-ROC: 0.9998958953004164\n",
      "MCC: 0.9858019891803284\n",
      "Precision: 0.9909638554216867\n",
      "F1 Score: 0.9908906134515891\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Load the EfficientNetB7 model pre-trained on ImageNet data\n",
    "efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers\n",
    "for layer in efficientnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build a new model using EfficientNetB7 as a feature extractor\n",
    "with tf.device('/GPU:0'):\n",
    "    model_efficientnet = Sequential()\n",
    "    model_efficientnet.add(efficientnet_model)\n",
    "    model_efficientnet.add(Flatten())\n",
    "    model_efficientnet.add(Dense(256, activation='relu', kernel_initializer='glorot_normal', bias_initializer='zeros'))\n",
    "    model_efficientnet.add(Dropout(0.5, seed=0))\n",
    "    model_efficientnet.add(Dense(num_classes, activation='softmax', kernel_initializer='glorot_normal', bias_initializer='zeros'))\n",
    "\n",
    "    # Compile the model\n",
    "    model_efficientnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    evaluate_model(model_efficientnet, 'EfficientNetB0', data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "755e0404-0539-4b5f-9425-ff9fa07252dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fold 1 / 10 for ResNet50\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 12s 66ms/step - loss: 12.1546 - accuracy: 0.6009\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.7307 - accuracy: 0.6802\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.6413 - accuracy: 0.7007\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.5798 - accuracy: 0.7499\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.5177 - accuracy: 0.7704\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.4910 - accuracy: 0.7755\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.4411 - accuracy: 0.8099\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.4247 - accuracy: 0.8161\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.3882 - accuracy: 0.8308\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.3538 - accuracy: 0.8560\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.3718 - accuracy: 0.8498\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.3412 - accuracy: 0.8564\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.3407 - accuracy: 0.8637\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.3445 - accuracy: 0.8630\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.2982 - accuracy: 0.8858\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.2779 - accuracy: 0.8893\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.2858 - accuracy: 0.8901\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.2513 - accuracy: 0.8997\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.2492 - accuracy: 0.9040\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.2301 - accuracy: 0.9172\n",
      "9/9 [==============================] - 3s 48ms/step\n",
      "Accuracy: 0.9512195121951219\n",
      "Sensitivity: 0.9542494556085505\n",
      "Specificity: 0.9833317906234091\n",
      "AUC-ROC: 0.9942775903976361\n",
      "MCC: 0.9340115195343844\n",
      "Precision: 0.9525136798905609\n",
      "F1 Score: 0.9527143255200337\n",
      "\n",
      "[INFO] Fold 2 / 10 for ResNet50\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 61ms/step - loss: 0.2627 - accuracy: 0.9168\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.2364 - accuracy: 0.9024\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.2264 - accuracy: 0.9113\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.2393 - accuracy: 0.9063\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1988 - accuracy: 0.9230\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.2043 - accuracy: 0.9206\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1978 - accuracy: 0.9330\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.2195 - accuracy: 0.9253\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1848 - accuracy: 0.9303\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1886 - accuracy: 0.9303\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1924 - accuracy: 0.9268\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1756 - accuracy: 0.9338\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1753 - accuracy: 0.9384\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1555 - accuracy: 0.9373\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1752 - accuracy: 0.9454\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1536 - accuracy: 0.9462\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1537 - accuracy: 0.9439\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1482 - accuracy: 0.9473\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1310 - accuracy: 0.9547\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1444 - accuracy: 0.9512\n",
      "9/9 [==============================] - 1s 24ms/step\n",
      "Accuracy: 0.9825783972125436\n",
      "Sensitivity: 0.9813946216385241\n",
      "Specificity: 0.9943133783804632\n",
      "AUC-ROC: 0.9986452043885758\n",
      "MCC: 0.9763337789015094\n",
      "Precision: 0.9783830620855938\n",
      "F1 Score: 0.9797483419825967\n",
      "\n",
      "[INFO] Fold 3 / 10 for ResNet50\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 61ms/step - loss: 0.1385 - accuracy: 0.9566\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1314 - accuracy: 0.9535\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1583 - accuracy: 0.9481\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1622 - accuracy: 0.9470\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 57ms/step - loss: 0.1361 - accuracy: 0.9566\n",
      "9/9 [==============================] - 1s 26ms/step\n",
      "Accuracy: 0.9895470383275261\n",
      "Sensitivity: 0.9909638554216867\n",
      "Specificity: 0.9963414634146341\n",
      "AUC-ROC: 1.0\n",
      "MCC: 0.9858473390126498\n",
      "Precision: 0.9911764705882353\n",
      "F1 Score: 0.9909450500329717\n",
      "\n",
      "[INFO] Fold 4 / 10 for ResNet50\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 61ms/step - loss: 0.1680 - accuracy: 0.9524\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.1501 - accuracy: 0.9497\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1697 - accuracy: 0.9408\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1682 - accuracy: 0.9396\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 57ms/step - loss: 0.1619 - accuracy: 0.9501\n",
      "9/9 [==============================] - 1s 25ms/step\n",
      "Accuracy: 0.9930313588850174\n",
      "Sensitivity: 0.993939171319424\n",
      "Specificity: 0.9975490196078431\n",
      "AUC-ROC: 1.0\n",
      "MCC: 0.9905372730655778\n",
      "Precision: 0.9941176470588236\n",
      "F1 Score: 0.9939749156773697\n",
      "\n",
      "[INFO] Fold 5 / 10 for ResNet50\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 62ms/step - loss: 0.1410 - accuracy: 0.9524\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1241 - accuracy: 0.9574\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1600 - accuracy: 0.9466\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1632 - accuracy: 0.9431\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 57ms/step - loss: 0.1523 - accuracy: 0.9454\n",
      "9/9 [==============================] - 1s 25ms/step\n",
      "Accuracy: 0.9965156794425087\n",
      "Sensitivity: 0.9969512195121951\n",
      "Specificity: 0.9987745098039216\n",
      "AUC-ROC: 1.0\n",
      "MCC: 0.9952605069764389\n",
      "Precision: 0.9970238095238095\n",
      "F1 Score: 0.9969692516806877\n",
      "\n",
      "[INFO] Fold 6 / 10 for ResNet50\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 60ms/step - loss: 0.1382 - accuracy: 0.9528\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.2294 - accuracy: 0.9187\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.2140 - accuracy: 0.9113\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 56ms/step - loss: 0.2014 - accuracy: 0.9230\n",
      "9/9 [==============================] - 1s 24ms/step\n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "AUC-ROC: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "[INFO] Fold 7 / 10 for ResNet50\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 61ms/step - loss: 0.1375 - accuracy: 0.9508\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1470 - accuracy: 0.9504\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1866 - accuracy: 0.9369\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 58ms/step - loss: 0.1935 - accuracy: 0.9261\n",
      "9/9 [==============================] - 1s 25ms/step\n",
      "Accuracy: 0.9860627177700348\n",
      "Sensitivity: 0.9878416103438142\n",
      "Specificity: 0.9951219512195122\n",
      "AUC-ROC: 1.0\n",
      "MCC: 0.981214848879062\n",
      "Precision: 0.9883720930232558\n",
      "F1 Score: 0.9878740824392999\n",
      "\n",
      "[INFO] Fold 8 / 10 for ResNet50\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 61ms/step - loss: 0.1387 - accuracy: 0.9504\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1645 - accuracy: 0.9400\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1702 - accuracy: 0.9485\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 57ms/step - loss: 0.1702 - accuracy: 0.9419\n",
      "9/9 [==============================] - 1s 24ms/step\n",
      "Accuracy: 0.9965156794425087\n",
      "Sensitivity: 0.9969512195121951\n",
      "Specificity: 0.998780487804878\n",
      "AUC-ROC: 1.0\n",
      "MCC: 0.9952673298180527\n",
      "Precision: 0.9969879518072289\n",
      "F1 Score: 0.9969511061535602\n",
      "\n",
      "[INFO] Fold 9 / 10 for ResNet50\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 62ms/step - loss: 0.1603 - accuracy: 0.9497\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.1463 - accuracy: 0.9504\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1839 - accuracy: 0.9299\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1571 - accuracy: 0.9446\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.1434 - accuracy: 0.9508\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1835 - accuracy: 0.9388\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1437 - accuracy: 0.9462\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.1401 - accuracy: 0.9493\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1589 - accuracy: 0.9497\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1784 - accuracy: 0.9388\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 2s 57ms/step - loss: 0.1580 - accuracy: 0.9466\n",
      "9/9 [==============================] - 1s 26ms/step\n",
      "Accuracy: 0.9965156794425087\n",
      "Sensitivity: 0.9969879518072289\n",
      "Specificity: 0.998780487804878\n",
      "AUC-ROC: 0.9999851279000596\n",
      "MCC: 0.9952674079957639\n",
      "Precision: 0.9969879518072289\n",
      "F1 Score: 0.9969696969696971\n",
      "\n",
      "[INFO] Fold 10 / 10 for ResNet50\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - 4s 61ms/step - loss: 0.1420 - accuracy: 0.9543\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.1256 - accuracy: 0.9601\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.1592 - accuracy: 0.9473\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.1574 - accuracy: 0.9493\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 2s 57ms/step - loss: 0.1311 - accuracy: 0.9543\n",
      "9/9 [==============================] - 1s 27ms/step\n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "AUC-ROC: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Load the ResNet50 model pre-trained on ImageNet data\n",
    "resnet50_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers\n",
    "for layer in resnet50_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build a new model using ResNet50 as a feature extractor\n",
    "with tf.device('/GPU:0'):\n",
    "    model_resnet50 = Sequential()\n",
    "    model_resnet50.add(resnet50_model)\n",
    "    model_resnet50.add(Flatten())\n",
    "    model_resnet50.add(Dense(256, activation='relu', kernel_initializer='glorot_normal', bias_initializer='zeros'))\n",
    "    model_resnet50.add(Dropout(0.5, seed=0))\n",
    "    model_resnet50.add(Dense(num_classes, activation='softmax', kernel_initializer='glorot_normal', bias_initializer='zeros'))\n",
    "\n",
    "    # Compile the model\n",
    "    model_resnet50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    evaluate_model(model_resnet50, 'ResNet50', data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12d62fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a CSV file\n",
    "results_df.to_csv('DS5_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53e08610-4212-476c-8792-3406ab2bbe44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Sensitivity</th>\n",
       "      <th>Average Specificity</th>\n",
       "      <th>Average AUC-ROC</th>\n",
       "      <th>Average MCC</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average F1 Score</th>\n",
       "      <th>Memory Used (MB)</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.756230</td>\n",
       "      <td>0.920093</td>\n",
       "      <td>0.907396</td>\n",
       "      <td>0.681493</td>\n",
       "      <td>0.762434</td>\n",
       "      <td>0.758225</td>\n",
       "      <td>416.191406</td>\n",
       "      <td>2894.500581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.602091</td>\n",
       "      <td>0.592826</td>\n",
       "      <td>0.863132</td>\n",
       "      <td>0.728495</td>\n",
       "      <td>0.486804</td>\n",
       "      <td>0.579902</td>\n",
       "      <td>0.551047</td>\n",
       "      <td>371.125000</td>\n",
       "      <td>173.700305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.802787</td>\n",
       "      <td>0.787635</td>\n",
       "      <td>0.932723</td>\n",
       "      <td>0.944165</td>\n",
       "      <td>0.738224</td>\n",
       "      <td>0.803705</td>\n",
       "      <td>0.784896</td>\n",
       "      <td>376.613281</td>\n",
       "      <td>119.695549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.894077</td>\n",
       "      <td>0.895515</td>\n",
       "      <td>0.964637</td>\n",
       "      <td>0.983295</td>\n",
       "      <td>0.857312</td>\n",
       "      <td>0.888012</td>\n",
       "      <td>0.889447</td>\n",
       "      <td>413.484375</td>\n",
       "      <td>122.244015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.907666</td>\n",
       "      <td>0.909982</td>\n",
       "      <td>0.969286</td>\n",
       "      <td>0.986747</td>\n",
       "      <td>0.875420</td>\n",
       "      <td>0.900003</td>\n",
       "      <td>0.903058</td>\n",
       "      <td>8644.351562</td>\n",
       "      <td>18597.837821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VGG16</td>\n",
       "      <td>0.990244</td>\n",
       "      <td>0.990854</td>\n",
       "      <td>0.996623</td>\n",
       "      <td>0.999536</td>\n",
       "      <td>0.986895</td>\n",
       "      <td>0.991405</td>\n",
       "      <td>0.990896</td>\n",
       "      <td>934.636719</td>\n",
       "      <td>174.985255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EfficientNetB0</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.986895</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.999463</td>\n",
       "      <td>0.980618</td>\n",
       "      <td>0.985942</td>\n",
       "      <td>0.986260</td>\n",
       "      <td>292.871094</td>\n",
       "      <td>166.702671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.989199</td>\n",
       "      <td>0.989928</td>\n",
       "      <td>0.996299</td>\n",
       "      <td>0.999291</td>\n",
       "      <td>0.985374</td>\n",
       "      <td>0.989556</td>\n",
       "      <td>0.989615</td>\n",
       "      <td>161.539062</td>\n",
       "      <td>230.242539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Average Accuracy  Average Sensitivity  Average Specificity  \\\n",
       "0              LR          0.766551             0.756230             0.920093   \n",
       "1              NB          0.602091             0.592826             0.863132   \n",
       "2             KNN          0.802787             0.787635             0.932723   \n",
       "3   Random Forest          0.894077             0.895515             0.964637   \n",
       "4            LGBM          0.907666             0.909982             0.969286   \n",
       "5           VGG16          0.990244             0.990854             0.996623   \n",
       "6  EfficientNetB0          0.985714             0.986895             0.995117   \n",
       "7        ResNet50          0.989199             0.989928             0.996299   \n",
       "\n",
       "   Average AUC-ROC  Average MCC  Average Precision  Average F1 Score  \\\n",
       "0         0.907396     0.681493           0.762434          0.758225   \n",
       "1         0.728495     0.486804           0.579902          0.551047   \n",
       "2         0.944165     0.738224           0.803705          0.784896   \n",
       "3         0.983295     0.857312           0.888012          0.889447   \n",
       "4         0.986747     0.875420           0.900003          0.903058   \n",
       "5         0.999536     0.986895           0.991405          0.990896   \n",
       "6         0.999463     0.980618           0.985942          0.986260   \n",
       "7         0.999291     0.985374           0.989556          0.989615   \n",
       "\n",
       "   Memory Used (MB)      Time (s)  \n",
       "0        416.191406   2894.500581  \n",
       "1        371.125000    173.700305  \n",
       "2        376.613281    119.695549  \n",
       "3        413.484375    122.244015  \n",
       "4       8644.351562  18597.837821  \n",
       "5        934.636719    174.985255  \n",
       "6        292.871094    166.702671  \n",
       "7        161.539062    230.242539  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc3aa5-9f81-477b-93c3-f9f1aaba4ef2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
